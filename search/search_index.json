{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"about/collaborators/","text":"Comming Soon...","title":"Collaborators"},{"location":"about/faqs/","text":"Why can't you register a Quartet Data Portal account by yourself? \u00b6 The reason there is no \"Register\" button is that the general process is for users to apply for reference materials as a guest first. This is to facilitate the confirmation of the applicant's information as well as to build a trust and consensus between the two parties, and at all times applicants should avoid uploading and analyzing non-Quartet data on our platform.","title":"FAQs"},{"location":"about/faqs/#why-cant-you-register-a-quartet-data-portal-account-by-yourself","text":"The reason there is no \"Register\" button is that the general process is for users to apply for reference materials as a guest first. This is to facilitate the confirmation of the applicant's information as well as to build a trust and consensus between the two parties, and at all times applicants should avoid uploading and analyzing non-Quartet data on our platform.","title":"Why can't you register a Quartet Data Portal account by yourself?"},{"location":"about/members/","text":"Comming Soon...","title":"Members"},{"location":"about/news/","text":"June 20, 2023 \u00b6 Documentation Improvement Improve some documents Release new version of quartet-protqc-report and related docker image quartet-protqc-report v0.2.4-6534a16b quartet-protqc-report v0.2.4-6534a16b June 19, 2023 \u00b6 Documentation Improvement Improve some documents Release new version of quartet-rseqc-report and related docker image Scale performance score to 1-10 and revised historical value quartet-rnaqc-report v0.2.4-15cd635b quartet-rnaqc-report v0.2.4-15cd635b June 3, 2023 \u00b6 Documentation Improvement Add more details about the policies (data request, data submission, account registration, reference materials). Mar 4, 2023 \u00b6 Documentation Improvement Add a document for the local version of DNA-seq qc report. Release docker images quartet-dnaqc-report Feb 17, 2023 \u00b6 Documentation Improvement Add a document for the local version of Proteomics qc report. Add a document for the local version of Metabolomics qc report. Add a document for the local version of RNA-seq qc report. Release docker images quartet-rseqc-report quartet-protqc-report quartet-metqc-report Oct 8, 2022 \u00b6 Documentation Improvement Add publications Add a document for proteomics qc report. Add a document for metabolomics qc report. Sep 7, 2022 \u00b6 DocSys Improvement Add a third-party comment system to the footer Add a language switcher in the header of doc (English and Chinese.) Documentation Improvement Add a Chinese document for ossutil Sep 6, 2022 \u00b6 Backend Improvement Add a new api for checking projects' status. Improve the DNA app to remove the limitations on file name. Improve the statistics of job process. UI Improvement Track your jobs with project status Documentation Improvement Update the document for data tranfer tools (The ossutil the preferred option.) April 15, 2022 \u00b6 Added new branch quartet-data-portal-dev for faster release. Release new features at any time, but its stability is not guaranteed. If you need a stable release, please access quartet-data-portal . quartet-data-portal-dev : http://dev.chinese-quartet.org quartet-data-portal : https://chinese-quartet.org Improved the performance: opening time of the first screen is from 5-6 seconds to 1-2 seconds.","title":"News"},{"location":"about/news/#june-20-2023","text":"Documentation Improvement Improve some documents Release new version of quartet-protqc-report and related docker image quartet-protqc-report v0.2.4-6534a16b quartet-protqc-report v0.2.4-6534a16b","title":"June 20, 2023"},{"location":"about/news/#june-19-2023","text":"Documentation Improvement Improve some documents Release new version of quartet-rseqc-report and related docker image Scale performance score to 1-10 and revised historical value quartet-rnaqc-report v0.2.4-15cd635b quartet-rnaqc-report v0.2.4-15cd635b","title":"June 19, 2023"},{"location":"about/news/#june-3-2023","text":"Documentation Improvement Add more details about the policies (data request, data submission, account registration, reference materials).","title":"June 3, 2023"},{"location":"about/news/#mar-4-2023","text":"Documentation Improvement Add a document for the local version of DNA-seq qc report. Release docker images quartet-dnaqc-report","title":"Mar 4, 2023"},{"location":"about/news/#feb-17-2023","text":"Documentation Improvement Add a document for the local version of Proteomics qc report. Add a document for the local version of Metabolomics qc report. Add a document for the local version of RNA-seq qc report. Release docker images quartet-rseqc-report quartet-protqc-report quartet-metqc-report","title":"Feb 17, 2023"},{"location":"about/news/#oct-8-2022","text":"Documentation Improvement Add publications Add a document for proteomics qc report. Add a document for metabolomics qc report.","title":"Oct 8, 2022"},{"location":"about/news/#sep-7-2022","text":"DocSys Improvement Add a third-party comment system to the footer Add a language switcher in the header of doc (English and Chinese.) Documentation Improvement Add a Chinese document for ossutil","title":"Sep 7, 2022"},{"location":"about/news/#sep-6-2022","text":"Backend Improvement Add a new api for checking projects' status. Improve the DNA app to remove the limitations on file name. Improve the statistics of job process. UI Improvement Track your jobs with project status Documentation Improvement Update the document for data tranfer tools (The ossutil the preferred option.)","title":"Sep 6, 2022"},{"location":"about/news/#april-15-2022","text":"Added new branch quartet-data-portal-dev for faster release. Release new features at any time, but its stability is not guaranteed. If you need a stable release, please access quartet-data-portal . quartet-data-portal-dev : http://dev.chinese-quartet.org quartet-data-portal : https://chinese-quartet.org Improved the performance: opening time of the first screen is from 5-6 seconds to 1-2 seconds.","title":"April 15, 2022"},{"location":"about/publications/","text":"Main Paper \u00b6 Zheng, Y. et al. Ratio-based multiomic profiling using universal reference materials empowers data integration [Unpublished manuscript]. (2022). Genomics \u00b6 Ren, L. et al. Quartet DNA reference materials and datasets for comprehensively evaluating germline variants calling performance [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.28.509844 Jia, P. et al. Haplotype-resolved assemblies and variant benchmark of a Chinese Quartet [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.08.504083 Transcriptomics \u00b6 Yu, Y. et al. Quartet RNA reference materials and ratio-based reference datasets for reliable transcriptomic profiling [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.26.507265 Proteomics \u00b6 Tian, S. et al. Quartet protein reference materials and datasets for multi-platform assessment of label-free proteomics [Unpublished manuscript] (2022) Metabolomics \u00b6 Quartet metabolite reference materials and datasets for inter-laboratory reliability assessment of metabolomics studies [Unpublished manuscript] (2022) Batch Effect \u00b6 Yu, Y. et al. Correcting batch effects in large-scale multiomic studies using a reference-material-based ratio method [Unpublished manuscript] (2022) Database & Webserver \u00b6 Yang, J. et al. The Quartet Data Portal: integration of community-wide resources for multiomics quality control [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.26.507202","title":"Publications"},{"location":"about/publications/#main-paper","text":"Zheng, Y. et al. Ratio-based multiomic profiling using universal reference materials empowers data integration [Unpublished manuscript]. (2022).","title":"Main Paper"},{"location":"about/publications/#genomics","text":"Ren, L. et al. Quartet DNA reference materials and datasets for comprehensively evaluating germline variants calling performance [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.28.509844 Jia, P. et al. Haplotype-resolved assemblies and variant benchmark of a Chinese Quartet [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.08.504083","title":"Genomics"},{"location":"about/publications/#transcriptomics","text":"Yu, Y. et al. Quartet RNA reference materials and ratio-based reference datasets for reliable transcriptomic profiling [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.26.507265","title":"Transcriptomics"},{"location":"about/publications/#proteomics","text":"Tian, S. et al. Quartet protein reference materials and datasets for multi-platform assessment of label-free proteomics [Unpublished manuscript] (2022)","title":"Proteomics"},{"location":"about/publications/#metabolomics","text":"Quartet metabolite reference materials and datasets for inter-laboratory reliability assessment of metabolomics studies [Unpublished manuscript] (2022)","title":"Metabolomics"},{"location":"about/publications/#batch-effect","text":"Yu, Y. et al. Correcting batch effects in large-scale multiomic studies using a reference-material-based ratio method [Unpublished manuscript] (2022)","title":"Batch Effect"},{"location":"about/publications/#database-webserver","text":"Yang, J. et al. The Quartet Data Portal: integration of community-wide resources for multiomics quality control [Unpublished manuscript] (2022) https://doi.org/10.1101/2022.09.26.507202","title":"Database &amp; Webserver"},{"location":"data_dictionary/about/","text":"","title":"About"},{"location":"data_dictionary/metadata/","text":"NOTES \u00b6 These fields are applicable to all omics technologies. If there is something you do not understand, please download the historical metadata at the Quartet Data Portal to learn more about its meaning. The \"from\" column indicates the source of the field. Metadata Schema \u00b6 key name short description type collection from project_id Project Id Project Id Identity of the project. category quartet project project_name Project Name Project Name Name of the project. category quartet project project_type Project Type Project Type Type of the project. category quartet project project_description Project Description Project Description Description of the project. category quartet project investigator_name Investigator Name Pi Name Name of the investigator. category quartet project investigator_affiliation Investigator Affiliation Pi Aff Affiliation of the investigator. category quartet project support_id Support Id Support Id ID of the project funded. category quartet project support_source Support Source Support Source Source of the project funded. category quartet project date_collected Date Collected Date Collect Collection date. number quartet project availability_type Availability Type Avail Type Data privacy. category quartet project donor_id Donor Id Donor Id Identity of the donor. category quartet donor family_id Family Id Family Id Identity of the family. category quartet donor pedigree Pedigree Pedigree Pedigree of the family category quartet donor gender Gender Gender Gender of the donor. category quartet donor birth_date Birth Date Birthday Birthday of the donor. number quartet donor biospecimen_id Biospecimen Id Biospecimen Id Identity of the biospecimen. category quartet biospecimen biospecimen_name Biospecimen Name Biospecimen Name Name of the biospecimen. category quartet biospecimen biospecimen_type Biospecimen Type Biospecimen Type Type of the biospecimen. category quartet biospecimen collection_date Collection Date Collect Date Sample collection date. number quartet biospecimen rm_id Rm Id Rm Id Identity of the RM. category quartet reference_materials extraction_site Extraction Site Extract Site Site of the extraction. category quartet reference_materials lot_no Lot No Lot No Number of batch. number quartet reference_materials cell_line_passage_number Cell Line Passage Number Clp Number Number of cell line passage. number quartet reference_materials rm_type Rm Type Rm Type Type of the RM. category quartet reference_materials source Source Source Source of the sample.(eg. Blood, cell, etc.) category quartet reference_materials cell_collection_date Cell Collection Date Cell Collect Date Data of cell collcollectionction. number quartet reference_materials extraction_date Extraction Date Extract Date Data of materials extraction. number quartet reference_materials kit_cat_no Kit Cat No Kit Cat No Number kit cat. number quartet reference_materials kit_lot_no Lot Lot No Kit Cat Number kit lot. number quartet reference_materials extraction_protocol Extraction Extract Protocol of extraction. number quartet reference_materials library_id Library Id Library Id Identity of the library. number quartet library input_ng Input Ng Input Ng Concentration of input. precision quartet library enrich_kit Enrich Kit Enrich Kit Kit of library enrichment. category quartet library preparation_kit Preparation Kit Prep Kit Kit of preperation. category quartet library fragment_method Fragment Method Fragment Method Method of the fragment. category quartet library fragment_selection Fragment Selection Fragment Select Selection of the fragment. category quartet library fragment_range Fragment Range Fragment Range Range of the fragment. precision quartet library pcr_cycle Pcr Cycle Pcr Cycle Cycle of PCR number quartet library preparation_date Preparation Date Prep Date Date of preperation. number quartet library spike_in Spike In Spike In Spike_in added in the library construction.PreparationpreparationPreparationpreparation category quartet library qc_concentration Qc Concentration Qc Conc Concentration of quality control. precision quartet library qc_size Qc Size Qc Size Size of quality control. precision quartet library preparation_method Preperation Method Prep Method Method of preparation. category quartet library preparation_site Preparation Site Prep Site Site of preparation category quartet library batch Library Batch Lib Batch Batch of library category quartet library stranded Library Type Lib Type Type of library category quartet library sequencing_id Sequencing Id Seq Id ID of sequencing. number quartet sequencing site Site Site Site of sequencing. category quartet sequencing platform Platform Platform Platform of sequencing. category quartet sequencing method Method Method Method of sequencing. category quartet sequencing index_sequence Index Sequence Index Seq Index of sequencing. category quartet sequencing flowcell_id Flowcell Id Flowcell Id Identity of the flowcell. category quartet sequencing lane_no Lane No Lane No Number of the lane. number quartet sequencing run_date Run Date Run Date Date of process running. number quartet sequencing datafile_id Datafile Id Datafile Id Identity of the data file. category quartet datafile submitter_id Submitter Id Submitter Id Identity of the submitter. category quartet datafile data_type Data Type Data Type Type of the data file. category quartet datafile data_category Data Category Data Cat Category of the data file. category quartet datafile data_format Data Format Data Format Format of the data file. category quartet datafile file_name File Name File Name Name of the data file. category quartet datafile file_size File Size File Size Size of the datafile. precision quartet datafile md_5sum Md5Sum Md5 The 128-bit hash value expressed as a 32 digit hexadecimal number (in lower case) used as a file's digital fingerprint. category quartet datafile file_path File Path File Path Path of the date file. category quartet datafile node Node Id Node Id Identity of the Node URL. category quartet datafile analyses_id Analyses Id Analyze Id Identity of the analyses. category quartet analyses analyses_type Analyses Type Analyze Type Type of the analyses. category quartet analyses link Link Link Link of the analyses. category quartet analyses version Version Version Version of the analyses. category quartet analyses","title":"Metadata"},{"location":"data_dictionary/metadata/#notes","text":"These fields are applicable to all omics technologies. If there is something you do not understand, please download the historical metadata at the Quartet Data Portal to learn more about its meaning. The \"from\" column indicates the source of the field.","title":"NOTES"},{"location":"data_dictionary/metadata/#metadata-schema","text":"key name short description type collection from project_id Project Id Project Id Identity of the project. category quartet project project_name Project Name Project Name Name of the project. category quartet project project_type Project Type Project Type Type of the project. category quartet project project_description Project Description Project Description Description of the project. category quartet project investigator_name Investigator Name Pi Name Name of the investigator. category quartet project investigator_affiliation Investigator Affiliation Pi Aff Affiliation of the investigator. category quartet project support_id Support Id Support Id ID of the project funded. category quartet project support_source Support Source Support Source Source of the project funded. category quartet project date_collected Date Collected Date Collect Collection date. number quartet project availability_type Availability Type Avail Type Data privacy. category quartet project donor_id Donor Id Donor Id Identity of the donor. category quartet donor family_id Family Id Family Id Identity of the family. category quartet donor pedigree Pedigree Pedigree Pedigree of the family category quartet donor gender Gender Gender Gender of the donor. category quartet donor birth_date Birth Date Birthday Birthday of the donor. number quartet donor biospecimen_id Biospecimen Id Biospecimen Id Identity of the biospecimen. category quartet biospecimen biospecimen_name Biospecimen Name Biospecimen Name Name of the biospecimen. category quartet biospecimen biospecimen_type Biospecimen Type Biospecimen Type Type of the biospecimen. category quartet biospecimen collection_date Collection Date Collect Date Sample collection date. number quartet biospecimen rm_id Rm Id Rm Id Identity of the RM. category quartet reference_materials extraction_site Extraction Site Extract Site Site of the extraction. category quartet reference_materials lot_no Lot No Lot No Number of batch. number quartet reference_materials cell_line_passage_number Cell Line Passage Number Clp Number Number of cell line passage. number quartet reference_materials rm_type Rm Type Rm Type Type of the RM. category quartet reference_materials source Source Source Source of the sample.(eg. Blood, cell, etc.) category quartet reference_materials cell_collection_date Cell Collection Date Cell Collect Date Data of cell collcollectionction. number quartet reference_materials extraction_date Extraction Date Extract Date Data of materials extraction. number quartet reference_materials kit_cat_no Kit Cat No Kit Cat No Number kit cat. number quartet reference_materials kit_lot_no Lot Lot No Kit Cat Number kit lot. number quartet reference_materials extraction_protocol Extraction Extract Protocol of extraction. number quartet reference_materials library_id Library Id Library Id Identity of the library. number quartet library input_ng Input Ng Input Ng Concentration of input. precision quartet library enrich_kit Enrich Kit Enrich Kit Kit of library enrichment. category quartet library preparation_kit Preparation Kit Prep Kit Kit of preperation. category quartet library fragment_method Fragment Method Fragment Method Method of the fragment. category quartet library fragment_selection Fragment Selection Fragment Select Selection of the fragment. category quartet library fragment_range Fragment Range Fragment Range Range of the fragment. precision quartet library pcr_cycle Pcr Cycle Pcr Cycle Cycle of PCR number quartet library preparation_date Preparation Date Prep Date Date of preperation. number quartet library spike_in Spike In Spike In Spike_in added in the library construction.PreparationpreparationPreparationpreparation category quartet library qc_concentration Qc Concentration Qc Conc Concentration of quality control. precision quartet library qc_size Qc Size Qc Size Size of quality control. precision quartet library preparation_method Preperation Method Prep Method Method of preparation. category quartet library preparation_site Preparation Site Prep Site Site of preparation category quartet library batch Library Batch Lib Batch Batch of library category quartet library stranded Library Type Lib Type Type of library category quartet library sequencing_id Sequencing Id Seq Id ID of sequencing. number quartet sequencing site Site Site Site of sequencing. category quartet sequencing platform Platform Platform Platform of sequencing. category quartet sequencing method Method Method Method of sequencing. category quartet sequencing index_sequence Index Sequence Index Seq Index of sequencing. category quartet sequencing flowcell_id Flowcell Id Flowcell Id Identity of the flowcell. category quartet sequencing lane_no Lane No Lane No Number of the lane. number quartet sequencing run_date Run Date Run Date Date of process running. number quartet sequencing datafile_id Datafile Id Datafile Id Identity of the data file. category quartet datafile submitter_id Submitter Id Submitter Id Identity of the submitter. category quartet datafile data_type Data Type Data Type Type of the data file. category quartet datafile data_category Data Category Data Cat Category of the data file. category quartet datafile data_format Data Format Data Format Format of the data file. category quartet datafile file_name File Name File Name Name of the data file. category quartet datafile file_size File Size File Size Size of the datafile. precision quartet datafile md_5sum Md5Sum Md5 The 128-bit hash value expressed as a 32 digit hexadecimal number (in lower case) used as a file's digital fingerprint. category quartet datafile file_path File Path File Path Path of the date file. category quartet datafile node Node Id Node Id Identity of the Node URL. category quartet datafile analyses_id Analyses Id Analyze Id Identity of the analyses. category quartet analyses analyses_type Analyses Type Analyze Type Type of the analyses. category quartet analyses link Link Link Link of the analyses. category quartet analyses version Version Version Version of the analyses. category quartet analyses","title":"Metadata Schema"},{"location":"data_dictionary/release_notes/","text":"","title":"Release notes"},{"location":"data_pipelines/intro/","text":"Genomics \u00b6 For whole-genome sequencing, the quality assessment is started from FASTQ files and can be divided into three parts: pre-alignment quality assessment, post-alignment assessment, and small variants calling results assessment. The quality of pre-alignment is assessed by FastQC and FastQ Screen, while post-alignment is assessed by Qualimap. The performance of variants calling results are evaluated by reference datasets and Quartet family-dependent built-in genetic truth. MultiQC was used for compiling QC results together. Pre-alignment and Post-alignment quality assessment are not available if user start from VCF files. Transcriptomics \u00b6 For RNA-seq, the quality assessment is started from FASTQ files and can be divided into three parts: pre-alignment, post-alignment, and gene-expression profiles. The quality of pre-alignment is assessed by FastQC and FastQ Screen, while post-alignment is assessed by Qualimap, while the quality control of gene expression profiles is based on the Quartet reference datasets and the internal information of each batch itself. MultiQC was used for compiling QC results together. Proteomics \u00b6 For proteomics, the quality assessment is started from expression profiles formatted as .csv files, and the pipeline is implemented into QC Report module. It is based on built-in biological differences of the samples and consistency with the reference dataset at relative quantitation levels. The former is scored as an Signal-to-Noise Ratio (SNR) and displayed in a PCA scatterplot, and the latter is scored as Pearson correlation to the reference dataset and displayed in a scatterplot, in which a strict filter criteria was applied (features with p.adj<0.05 in at least 4 batches were kept). MultiQC was used for compiling QC results together. Metabolomics \u00b6 Quality Assessment of a Quartet metabolic profiling dataset is based on built-in biological differences of the samples, consistency with the reference dataset at relative quantitation levels. The three QC metrics, including Signal-to-Noise Ratio (SNR), Relative Correlation with Reference Datasets (RC), and Recall of DAMs in Reference Datasets (Recall), to comprehensively assess the performance of metabolic profiles from 2 aspects: reproducibility and accuracy.","title":"Introduction"},{"location":"data_pipelines/intro/#genomics","text":"For whole-genome sequencing, the quality assessment is started from FASTQ files and can be divided into three parts: pre-alignment quality assessment, post-alignment assessment, and small variants calling results assessment. The quality of pre-alignment is assessed by FastQC and FastQ Screen, while post-alignment is assessed by Qualimap. The performance of variants calling results are evaluated by reference datasets and Quartet family-dependent built-in genetic truth. MultiQC was used for compiling QC results together. Pre-alignment and Post-alignment quality assessment are not available if user start from VCF files.","title":"Genomics"},{"location":"data_pipelines/intro/#transcriptomics","text":"For RNA-seq, the quality assessment is started from FASTQ files and can be divided into three parts: pre-alignment, post-alignment, and gene-expression profiles. The quality of pre-alignment is assessed by FastQC and FastQ Screen, while post-alignment is assessed by Qualimap, while the quality control of gene expression profiles is based on the Quartet reference datasets and the internal information of each batch itself. MultiQC was used for compiling QC results together.","title":"Transcriptomics"},{"location":"data_pipelines/intro/#proteomics","text":"For proteomics, the quality assessment is started from expression profiles formatted as .csv files, and the pipeline is implemented into QC Report module. It is based on built-in biological differences of the samples and consistency with the reference dataset at relative quantitation levels. The former is scored as an Signal-to-Noise Ratio (SNR) and displayed in a PCA scatterplot, and the latter is scored as Pearson correlation to the reference dataset and displayed in a scatterplot, in which a strict filter criteria was applied (features with p.adj<0.05 in at least 4 batches were kept). MultiQC was used for compiling QC results together.","title":"Proteomics"},{"location":"data_pipelines/intro/#metabolomics","text":"Quality Assessment of a Quartet metabolic profiling dataset is based on built-in biological differences of the samples, consistency with the reference dataset at relative quantitation levels. The three QC metrics, including Signal-to-Noise Ratio (SNR), Relative Correlation with Reference Datasets (RC), and Recall of DAMs in Reference Datasets (Recall), to comprehensively assess the performance of metabolic profiles from 2 aspects: reproducibility and accuracy.","title":"Metabolomics"},{"location":"data_pipelines/genomics/analysis_pipeline/","text":"Quality control pipeline for WGS \u00b6 This Quartet quality control pipeline evaluate the performance of reads quality and variant calling quality. This pipeline accepts FASTQ format input files or VCF format input files. If the users input FASTQ files, this APP will output the results of pre-alignment quality control from FASTQ files, post-alignment quality control from BAM files and variant calling quality control from VCF files. GATK best practice pipelines (implemented by SENTIEON software ) were used to map reads to the reference genome and call variants. If the users input VCF files, this APP will only output the results of variant calling quality control. Quartet quality control analysis pipeline started from FASTQ files is implemented across seven main procedures: Pre-alignment QC of FASTQ files Genome alignment Post-alignment QC of BAM files Germline variant calling Variant calling QC depended on benchmark sets of VCF files Check Mendelian inheritance states across four Quartet samples of every variants Variant calling QC depended on Quartet genetic relationship of VCF files Quartet quality control analysis pipeline started from VCF files is implemented across three main procedures: Variant calling QC depended on benchmark sets of VCF files Check Mendelian inheritance states across four Quartet samples of every variants Variant calling QC depended on Quartet genetic relationship of VCF files Results generated from this APP can be visualized by QDP report. 1. Pre-alignment QC of FASTQ files \u00b6 Fastqc v0.11.5 \u00b6 FastQC is used to investigate the quality of fastq files fastqc -t <threads> -o <output_directory> <fastq_file> Fastq Screen 0.12.0 \u00b6 Fastq Screen is used to inspect whether the library were contaminated. For example, we expected 99% reads aligned to human genome, 10% reads aligned to mouse genome, which is partly homologous to human genome. If too many reads are aligned to E.Coli or Yeast, libraries or cell lines are probably comtminated. fastq_screen --aligner <aligner> --conf <config_file> --top <number_of_reads> --threads <threads> <fastq_file> 2. Genome alignment \u00b6 sentieon-genomics :v2019.11.28 \u00b6 Reads were mapped to the human reference genome GRCh38 using Sentieon BWA. ${ SENTIEON_INSTALL_DIR } /bin/bwa mem -M -R \"@RG\\tID: ${ group } \\tSM: ${ sample } \\tPL: ${ pl } \" -t $nt -K 10000000 ${ ref_dir } / ${ fasta } ${ fastq_1 } ${ fastq_2 } | ${ SENTIEON_INSTALL_DIR } /bin/sentieon util sort -o ${ sample } .sorted.bam -t $nt --sam2bam -i - 3. Post-alignment QC \u00b6 Qualimap and Paicard Tools (implemented by Sentieon) are used to check the quality of BAM files. Deduplicated BAM files are used in this step. Qualimap 2.0.0 \u00b6 qualimap bamqc -bam <bam_file> -outformat PDF:HTML -nt <threads> -outdir <output_directory> --java-mem-size = 32G Sentieon-genomics :v2019.11.28 \u00b6 ${SENTIEON_INSTALL_DIR}/bin/sentieon driver -r ${ref_dir}/${fasta} -t $nt -i ${Dedup_bam} --algo CoverageMetrics --omit_base_output ${sample}_deduped_coverage_metrics --algo MeanQualityByCycle ${sample}_deduped_mq_metrics.txt --algo QualDistribution ${sample}_deduped_qd_metrics.txt --algo GCBias --summary ${sample}_deduped_gc_summary.txt ${sample}_deduped_gc_metrics.txt --algo AlignmentStat ${sample}_deduped_aln_metrics.txt --algo InsertSizeMetricAlgo ${sample}_deduped_is_metrics.txt --algo QualityYield ${sample}_deduped_QualityYield.txt --algo WgsMetricsAlgo ${sample}_deduped_WgsMetricsAlgo.txt 4. Germline variant calling \u00b6 HaplotyperCaller implemented by Sentieon is used to identify germline variants. ${ SENTIEON_INSTALL_DIR } /bin/sentieon driver -r ${ ref_dir } / ${ fasta } -t $nt -i ${ recaled_bam } --algo Haplotyper ${ sample } _hc.vcf 5. Variants Calling QC \u00b6 5.1 Performance assessment based on benchmark sets \u00b6 Hap.py v0.3.9 \u00b6 Variants were compared with benchmark calls in benchmark regions. hap.py <truth_vcf> <query_vcf> -f <bed_file> --threads <threads> -o <output_filename> 5.2 Performance assessment based on Quartet genetic built-in truth \u00b6 VBT v1.1 \u00b6 We splited the Quartet family to two trios (F7, M8, D5 and F7, M8, D6) and then do the Mendelian analysis. A Quartet Mendelian concordant variant is the same between the twins (D5 and D6) , and follow the Mendelian concordant between parents (F7 and M8). Mendelian concordance rate is the Mendelian concordance variant divided by total detected variants in a Quartet family. Only variants on chr1-22,X are included in this analysis. vbt mendelian -ref <fasta_file> -mother <family_merged_vcf> -father <family_merged_vcf> -child <family_merged_vcf> -pedigree <ped_file> -outDir <output_directory> -out-prefix <output_directory_prefix> --output-violation-regions -thread-count <threads> Input files \u00b6 1. Start from Fastq files \u00b6 sample_id,project,fastq_1_D5,fastq_2_D5,fastq_1_D6,fastq_2_D6,fastq_1_F7,fastq_2_F7,fastq_1_M8,fastq_2_M8 # sample_id in choppy system # project name # oss path of D5 fastq read1 file # oss path of D5 fastq read2 file # oss path of D6 fastq read1 file # oss path of D6 fastq read2 file # oss path of F7 fastq read1 file # oss path of F7 fastq read2 file # oss path of M8 fastq read1 file # oss path of M8 fastq read2 file 2. Start from VCF files \u00b6 sample_id,project,vcf_D5,vcf_D6,vcf_F7,vcf_M8 # sample_id in choppy system # project name # oss path of D5 VCF file # oss path of D6 VCF file # oss path of F7 VCF file # oss path of M8 VCF file Output Files \u00b6 1. extract_tables.wdl/extract_tables_vcf.wdl \u00b6 (FASTQ) Pre-alignment QC: pre_alignment.txt (FASTQ) Post-alignment QC: post_alignment.txt (FASTQ/VCF) Variants calling QC: variants.calling.qc.txt 2. quartet_mendelian.wdl \u00b6 (FASTQ/VCF) Variants calling QC: mendelian.txt Output files format \u00b6 1. pre_alignment.txt \u00b6 Column name Description Sample Sample name %Dup Percentage duplicate reads %GC Average GC percentage Total Sequences (million) Total sequences %Human Percentage of reads mapped to human genome %EColi Percentage of reads mapped to Ecoli %Adapter Percentage of reads mapped to adapter %Vector Percentage of reads mapped to vector %rRNA Percentage of reads mapped to rRNA %Virus Percentage of reads mapped to virus %Yeast Percentage of reads mapped to yeast %Mitoch Percentage of reads mapped to mitochondrion %No hits Percentage of reads not mapped to genomes mentioned above 2. post_alignment.txt \u00b6 Column name Description Sample Sample name %Mapping Percentage of mapped reads %Mismatch Rate Mapping error rate Mendelian Insert Size Median insert size\uff08bp\uff09 %Q20 Percentage of bases >Q20 %Q30 Percentage of bases >Q30 Mean Coverage Mean deduped coverage Median Coverage Median deduped coverage PCT_1X Fraction of genome with at least 1x coverage PCT_5X Fraction of genome with at least 5x coverage PCT_10X Fraction of genome with at least 10x coverage PCT_30X Fraction of genome with at least 30x coverage 3. variants.calling.qc.txt \u00b6 Column name Description Sample Sample name SNV number Total SNV number (chr1-22,X) INDEL number Total INDEL number (chr1-22,X) SNV query SNV number in benchmark region INDEL query INDEL number in benchmark region SNV TP True positive SNV INDEL TP True positive INDEL SNV FP False positive SNV INDEL FP True positive INDEL SNV FN False negative SNV INDEL FN False negative INDEL SNV precision Precision of SNV calls when compared with benchmark calls in benchmark regions INDEL precision Precision of INDEL calls when compared with benchmark calls in benchmark regions SNV recall Recall of SNV calls when compared with benchmark calls in benchmark regions INDEL recall Recall of INDEL calls when compared with benchmark calls in benchmark regions SNV F1 F1 score of SNV calls when compared with benchmark calls in benchmark regions INDEL F1 F1 score of INDEL calls when compared with benchmark calls in benchmark regions 4 {project}.summary.txt \u00b6 Column name Description Family Family name defined by inputed project name Reproducibility_D5_D6 Percentage of variants were shared by the twins (D5 and D6) Mendelian_Concordance_Quartet Percentage of variants were Mendelian concordance","title":"Analysis Pipeline for WGS & WES"},{"location":"data_pipelines/genomics/analysis_pipeline/#quality-control-pipeline-for-wgs","text":"This Quartet quality control pipeline evaluate the performance of reads quality and variant calling quality. This pipeline accepts FASTQ format input files or VCF format input files. If the users input FASTQ files, this APP will output the results of pre-alignment quality control from FASTQ files, post-alignment quality control from BAM files and variant calling quality control from VCF files. GATK best practice pipelines (implemented by SENTIEON software ) were used to map reads to the reference genome and call variants. If the users input VCF files, this APP will only output the results of variant calling quality control. Quartet quality control analysis pipeline started from FASTQ files is implemented across seven main procedures: Pre-alignment QC of FASTQ files Genome alignment Post-alignment QC of BAM files Germline variant calling Variant calling QC depended on benchmark sets of VCF files Check Mendelian inheritance states across four Quartet samples of every variants Variant calling QC depended on Quartet genetic relationship of VCF files Quartet quality control analysis pipeline started from VCF files is implemented across three main procedures: Variant calling QC depended on benchmark sets of VCF files Check Mendelian inheritance states across four Quartet samples of every variants Variant calling QC depended on Quartet genetic relationship of VCF files Results generated from this APP can be visualized by QDP report.","title":"Quality control pipeline for WGS"},{"location":"data_pipelines/genomics/analysis_pipeline/#1-pre-alignment-qc-of-fastq-files","text":"","title":"1. Pre-alignment QC of FASTQ files"},{"location":"data_pipelines/genomics/analysis_pipeline/#fastqc-v0115","text":"FastQC is used to investigate the quality of fastq files fastqc -t <threads> -o <output_directory> <fastq_file>","title":"Fastqc v0.11.5"},{"location":"data_pipelines/genomics/analysis_pipeline/#fastq-screen-0120","text":"Fastq Screen is used to inspect whether the library were contaminated. For example, we expected 99% reads aligned to human genome, 10% reads aligned to mouse genome, which is partly homologous to human genome. If too many reads are aligned to E.Coli or Yeast, libraries or cell lines are probably comtminated. fastq_screen --aligner <aligner> --conf <config_file> --top <number_of_reads> --threads <threads> <fastq_file>","title":"Fastq Screen 0.12.0"},{"location":"data_pipelines/genomics/analysis_pipeline/#2-genome-alignment","text":"","title":"2. Genome alignment"},{"location":"data_pipelines/genomics/analysis_pipeline/#sentieon-genomicsv20191128","text":"Reads were mapped to the human reference genome GRCh38 using Sentieon BWA. ${ SENTIEON_INSTALL_DIR } /bin/bwa mem -M -R \"@RG\\tID: ${ group } \\tSM: ${ sample } \\tPL: ${ pl } \" -t $nt -K 10000000 ${ ref_dir } / ${ fasta } ${ fastq_1 } ${ fastq_2 } | ${ SENTIEON_INSTALL_DIR } /bin/sentieon util sort -o ${ sample } .sorted.bam -t $nt --sam2bam -i -","title":"sentieon-genomics:v2019.11.28"},{"location":"data_pipelines/genomics/analysis_pipeline/#3-post-alignment-qc","text":"Qualimap and Paicard Tools (implemented by Sentieon) are used to check the quality of BAM files. Deduplicated BAM files are used in this step.","title":"3. Post-alignment QC"},{"location":"data_pipelines/genomics/analysis_pipeline/#qualimap-200","text":"qualimap bamqc -bam <bam_file> -outformat PDF:HTML -nt <threads> -outdir <output_directory> --java-mem-size = 32G","title":"Qualimap 2.0.0"},{"location":"data_pipelines/genomics/analysis_pipeline/#sentieon-genomicsv20191128_1","text":"${SENTIEON_INSTALL_DIR}/bin/sentieon driver -r ${ref_dir}/${fasta} -t $nt -i ${Dedup_bam} --algo CoverageMetrics --omit_base_output ${sample}_deduped_coverage_metrics --algo MeanQualityByCycle ${sample}_deduped_mq_metrics.txt --algo QualDistribution ${sample}_deduped_qd_metrics.txt --algo GCBias --summary ${sample}_deduped_gc_summary.txt ${sample}_deduped_gc_metrics.txt --algo AlignmentStat ${sample}_deduped_aln_metrics.txt --algo InsertSizeMetricAlgo ${sample}_deduped_is_metrics.txt --algo QualityYield ${sample}_deduped_QualityYield.txt --algo WgsMetricsAlgo ${sample}_deduped_WgsMetricsAlgo.txt","title":"Sentieon-genomics:v2019.11.28"},{"location":"data_pipelines/genomics/analysis_pipeline/#4-germline-variant-calling","text":"HaplotyperCaller implemented by Sentieon is used to identify germline variants. ${ SENTIEON_INSTALL_DIR } /bin/sentieon driver -r ${ ref_dir } / ${ fasta } -t $nt -i ${ recaled_bam } --algo Haplotyper ${ sample } _hc.vcf","title":"4. Germline variant calling"},{"location":"data_pipelines/genomics/analysis_pipeline/#5-variants-calling-qc","text":"","title":"5. Variants Calling QC"},{"location":"data_pipelines/genomics/analysis_pipeline/#51-performance-assessment-based-on-benchmark-sets","text":"","title":"5.1 Performance assessment based on benchmark sets"},{"location":"data_pipelines/genomics/analysis_pipeline/#happy-v039","text":"Variants were compared with benchmark calls in benchmark regions. hap.py <truth_vcf> <query_vcf> -f <bed_file> --threads <threads> -o <output_filename>","title":"Hap.py v0.3.9"},{"location":"data_pipelines/genomics/analysis_pipeline/#52-performance-assessment-based-on-quartet-genetic-built-in-truth","text":"","title":"5.2 Performance assessment based on Quartet genetic built-in truth"},{"location":"data_pipelines/genomics/analysis_pipeline/#vbt-v11","text":"We splited the Quartet family to two trios (F7, M8, D5 and F7, M8, D6) and then do the Mendelian analysis. A Quartet Mendelian concordant variant is the same between the twins (D5 and D6) , and follow the Mendelian concordant between parents (F7 and M8). Mendelian concordance rate is the Mendelian concordance variant divided by total detected variants in a Quartet family. Only variants on chr1-22,X are included in this analysis. vbt mendelian -ref <fasta_file> -mother <family_merged_vcf> -father <family_merged_vcf> -child <family_merged_vcf> -pedigree <ped_file> -outDir <output_directory> -out-prefix <output_directory_prefix> --output-violation-regions -thread-count <threads>","title":"VBT v1.1"},{"location":"data_pipelines/genomics/analysis_pipeline/#input-files","text":"","title":"Input files"},{"location":"data_pipelines/genomics/analysis_pipeline/#1-start-from-fastq-files","text":"sample_id,project,fastq_1_D5,fastq_2_D5,fastq_1_D6,fastq_2_D6,fastq_1_F7,fastq_2_F7,fastq_1_M8,fastq_2_M8 # sample_id in choppy system # project name # oss path of D5 fastq read1 file # oss path of D5 fastq read2 file # oss path of D6 fastq read1 file # oss path of D6 fastq read2 file # oss path of F7 fastq read1 file # oss path of F7 fastq read2 file # oss path of M8 fastq read1 file # oss path of M8 fastq read2 file","title":"1. Start from Fastq files"},{"location":"data_pipelines/genomics/analysis_pipeline/#2-start-from-vcf-files","text":"sample_id,project,vcf_D5,vcf_D6,vcf_F7,vcf_M8 # sample_id in choppy system # project name # oss path of D5 VCF file # oss path of D6 VCF file # oss path of F7 VCF file # oss path of M8 VCF file","title":"2. Start from VCF files"},{"location":"data_pipelines/genomics/analysis_pipeline/#output-files","text":"","title":"Output Files"},{"location":"data_pipelines/genomics/analysis_pipeline/#1-extract_tableswdlextract_tables_vcfwdl","text":"(FASTQ) Pre-alignment QC: pre_alignment.txt (FASTQ) Post-alignment QC: post_alignment.txt (FASTQ/VCF) Variants calling QC: variants.calling.qc.txt","title":"1. extract_tables.wdl/extract_tables_vcf.wdl"},{"location":"data_pipelines/genomics/analysis_pipeline/#2-quartet_mendelianwdl","text":"(FASTQ/VCF) Variants calling QC: mendelian.txt","title":"2. quartet_mendelian.wdl"},{"location":"data_pipelines/genomics/analysis_pipeline/#output-files-format","text":"","title":"Output files format"},{"location":"data_pipelines/genomics/analysis_pipeline/#1-pre_alignmenttxt","text":"Column name Description Sample Sample name %Dup Percentage duplicate reads %GC Average GC percentage Total Sequences (million) Total sequences %Human Percentage of reads mapped to human genome %EColi Percentage of reads mapped to Ecoli %Adapter Percentage of reads mapped to adapter %Vector Percentage of reads mapped to vector %rRNA Percentage of reads mapped to rRNA %Virus Percentage of reads mapped to virus %Yeast Percentage of reads mapped to yeast %Mitoch Percentage of reads mapped to mitochondrion %No hits Percentage of reads not mapped to genomes mentioned above","title":"1. pre_alignment.txt"},{"location":"data_pipelines/genomics/analysis_pipeline/#2-post_alignmenttxt","text":"Column name Description Sample Sample name %Mapping Percentage of mapped reads %Mismatch Rate Mapping error rate Mendelian Insert Size Median insert size\uff08bp\uff09 %Q20 Percentage of bases >Q20 %Q30 Percentage of bases >Q30 Mean Coverage Mean deduped coverage Median Coverage Median deduped coverage PCT_1X Fraction of genome with at least 1x coverage PCT_5X Fraction of genome with at least 5x coverage PCT_10X Fraction of genome with at least 10x coverage PCT_30X Fraction of genome with at least 30x coverage","title":"2. post_alignment.txt"},{"location":"data_pipelines/genomics/analysis_pipeline/#3-variantscallingqctxt","text":"Column name Description Sample Sample name SNV number Total SNV number (chr1-22,X) INDEL number Total INDEL number (chr1-22,X) SNV query SNV number in benchmark region INDEL query INDEL number in benchmark region SNV TP True positive SNV INDEL TP True positive INDEL SNV FP False positive SNV INDEL FP True positive INDEL SNV FN False negative SNV INDEL FN False negative INDEL SNV precision Precision of SNV calls when compared with benchmark calls in benchmark regions INDEL precision Precision of INDEL calls when compared with benchmark calls in benchmark regions SNV recall Recall of SNV calls when compared with benchmark calls in benchmark regions INDEL recall Recall of INDEL calls when compared with benchmark calls in benchmark regions SNV F1 F1 score of SNV calls when compared with benchmark calls in benchmark regions INDEL F1 F1 score of INDEL calls when compared with benchmark calls in benchmark regions","title":"3. variants.calling.qc.txt"},{"location":"data_pipelines/genomics/analysis_pipeline/#4-projectsummarytxt","text":"Column name Description Family Family name defined by inputed project name Reproducibility_D5_D6 Percentage of variants were shared by the twins (D5 and D6) Mendelian_Concordance_Quartet Percentage of variants were Mendelian concordance","title":"4 {project}.summary.txt"},{"location":"data_pipelines/genomics/intro/","text":"Chinese Quartet DNA reference materials \u00b6 With the rapid development of sequencing technology and the dramatic decrease of sequencing costs, DNA sequencing has been widely used in scientific research, diagnosis of and treatment selection for human diseases. However, due to the lack of effective quality assessment and control of the high-throughput omics data generation and analysis processes, variants calling results are seriously inconsistent among different technical replicates, batches, laboratories, sequencing platforms, and analysis pipelines, resulting in irreproducible scientific results and conclusions, huge waste of resources, and even endangering the life and health of patients. Therefore, reference materials for quality control of the whole process from omics data generation to data analysis are urgently needed. We first established genomic DNA reference materials from four immortalized B-lymphoblastoid cell lines of a Chinese Quartet family including parents and monozygotic twin daughters to make performance assessment of germline variants calling results. To establish small variant benchmark calls and regions, we generated whole-genome sequencing data in nine batches, with depth ranging from 30x to 60x, by employing PCR-free and PCR libraries on four popular short-read sequencing platforms (Illumina HiSeq XTen, Illumina NovaSeq, MGISEQ-2000, and DNBSEQ-T7) with three replicates at each batch, resulting in 108 libraries in total and 27 libraries for each Quartet DNA reference material. Then, we selected variants concordant in multiple call sets and in Mendelian consistency within Quartet family members as small variant benchmark calls, resulting in 4.2 million high-confidence variants (SNV and Indel) and 2.66 G high confidence genomic region, covering 87.8% of the human reference genome (GRCh38, chr1-22 and X). Two orthogonal technologies were used for verifying the high-confidence variants. The consistency rate with PMRA (Axiom Precision Medicine Research Array) was 99.6%, and 95.9% of high-confidence variants were validated by 10X Genomics whole-genome sequencing data. Genetic built-in truth of the Quartet family design is another kind of \u201ctruth\u201d within the four Quartet samples. Apart from comparison with benchmark calls in the benchmark regions to identify false-positive and false-negative variants, pedigree information among the Quartet DNA reference materials, i.e., reproducibility rate of variants between the twins and Mendelian concordance rate among family members, are complementary approaches to comprehensively estimate genome-wide variants calling performance. Finally, we developed a whole-genome sequencing data quality assessment pipeline and demonstrated its utilities with two examples of using the Quartet reference materials and datasets to evaluate data generation performance in three sequencing labs and different data analysis pipelines. Requirements for your data and metadata \u00b6 Metadata Template - Download the metadata template and prepare your metabata Data Format - Follow the data format requirements to prepare your genomics data Analyze your data on Quartet Data Portal \u00b6 See more details on Step by Step Guide Analyze your data on your own server \u00b6 Quartet DSeQC Report is a quality assessment tool for WGS/WES data. It supports two format: Fastq and vcf . And it contains three subcommands: fq-workflow , vcf-workflow and report . The fq-workflow command takes raw reads (in FASTQ format), produces a set of qc result files from them (More details on DNA-Seq (WGS) QC for Quartet and DNA-Seq (WES) QC for Quartet ). When you have produced vcf files from your own pipeline, you can use the vcf-workflow command. It takes vcf files and produces a set of qc result files from them. After above processes, you can use report command to report the results finally (More details on QC Report for Quartet RNA-Seq ). If you have raw reads (in FASTQ format) \u00b6 CAUTION The pipeline for raw reads depends on Sentieon software. So if you want to use the pipeline, you need to specify the license server by -S option. If you don't have the license, we recommend you analyze your data on Quartet Data Portal . If not, please contact Sentieon or use the vcf mode. If you have your own pipeline, you can use your own pipeline to produce vcf files from your raw reads. Then you can use the vcf-workflow command to analyze your data. More details at the following section. [STATEMENT: We don't have any relationship with Sentieon and don't get any benefit from Sentieon.] Assuming your data files are in the /your-dir directory. Prepare a set of subdirectories mkdir -p /your-dir/raw-data /your-dir/references /your-dir/results /your-dir/report Download the dependency files wget https://zenodo.org/record/7800049/files/quartet-dseqc-report-reference-data-v20230404.zip?download=1 unzip quartet-dseqc-report-reference-data-v20230404.zip # You need to place the reference files into /your-dir/references directory Place your data files into /your-dir/raw-data directory Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a Generate qc result files by workflow command # For WGS Fastq data ## Assume the following conditions: ### 1. Your file name is like: d5.R1.gz, d5.R2.gz, d6.R1.gz, d6.R2.gz, f7.R1.gz, f7.R2.gz, m8.R1.gz, m8.R2.gz ### 2. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103, GRCh38.d1.vd1 and fastq_screen_reference directories. [You can follow the step 1 to download the reference files.] ### 3. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 4. The pipeline depends on Sentieon software, you need to specify -S to set the license server. ### 5. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a fq-workflow --d5-r1 /data/raw-data/d5.R1.gz --d5-r2 /data/raw-data/d5.R2.gz --d6-r1 /data/raw-data/d6.R1.gz --d6-r2 /data/raw-data/d6.R2.gz --f7-r1 /data/raw-data/f7.R1.gz --f7-r2 /data/raw-data/f7.R2.gz --m8-r1 /data/raw-data/m8.R1.gz --m8-r2 /data/raw-data/m8.R2.gz -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 -F /data/references/fastq_screen_reference -S 192.168.1.1:8990 --output-dir /data/results # For WES Fastq data ## Assume the following conditions: ### 1. Your file name is like: d5.R1.gz, d5.R2.gz, d6.R1.gz, d6.R2.gz, f7.R1.gz, f7.R2.gz, m8.R1.gz, m8.R2.gz ### 2. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103, GRCh38.d1.vd1 and fastq_screen_reference directories. [You can follow the step 1 to download the reference files.] ### 3. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 4. The pipeline depends on Sentieon software, you need to specify -S to set the license server. ### 5. You need to prepare your bed file and set -b option. ### 6. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a fq-workflow --d5-r1 /data/raw-data/d5.R1.gz --d5-r2 /data/raw-data/d5.R2.gz --d6-r1 /data/raw-data/d6.R1.gz --d6-r2 /data/raw-data/d6.R2.gz --f7-r1 /data/raw-data/f7.R1.gz --f7-r2 /data/raw-data/f7.R2.gz --m8-r1 /data/raw-data/m8.R1.gz --m8-r2 /data/raw-data/m8.R2.gz -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 -F /data/references/fastq_screen_reference -S 192.168.1.1:8990 --bed-file /data/references/your-bed-file --output-dir /data/results Report the results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a report -d /data/results --output-dir /data/report Find your QC report in /your-dir/report/multiqc_report.html If you have vcf files \u00b6 Assuming your data files are in the /your-dir directory. Prepare a set of subdirectories mkdir -p /your-dir/raw-data /your-dir/references /your-dir/results /your-dir/report Download the dependency files wget https://zenodo.org/record/7800049/files/quartet-dseqc-report-reference-data-v20230404.zip?download=1 unzip quartet-dseqc-report-reference-data-v20230404.zip # You need to place the reference files into /your-dir/references directory Place your data files into /your-dir/raw-data directory Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a Generate qc result files by workflow command # For WGS data ## Assume the following conditions: ### 1. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103 and GRCh38.d1.vd1 directories. [You can follow the step 1 to download the reference files.] ### 2. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 3. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a vcf-workflow --vcf-d5 /data/raw-data/d5.vcf --vcf-d6 /data/raw-data/d6.vcf --vcf-f7 /data/raw-data/f7.vcf --vcf-m8 /data/raw-data/m8.vcf -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 --output-dir /data/results # For WES data ## Assume the following conditions: ### 1. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103 and GRCh38.d1.vd1 directories. [You can follow the step 1 to download the reference files.] ### 2. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 3. You need to prepare your bed file and set -b option. ### 4. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a vcf-workflow --vcf-d5 /data/raw-data/d5.vcf --vcf-d6 /data/raw-data/d6.vcf --vcf-f7 /data/raw-data/f7.vcf --vcf-m8 /data/raw-data/m8.vcf -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 --bed-file /data/references/your-bed-file --output-dir /data/results Report the results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a report -d /data/results --output-dir /data/report # Known issue: # Only support one uuid directory in /your-dir/results directory. # If you have multiple uuid directories in /your-dir/results directory, the report will be failed or messy. # We will fix this issue in the future. Find your QC report in /your-dir/report/multiqc_report.html More details about the analysis pipeline \u00b6 QC APP - WGS QC for Quartet QC APP - WES QC for Quartet","title":"Introduction"},{"location":"data_pipelines/genomics/intro/#chinese-quartet-dna-reference-materials","text":"With the rapid development of sequencing technology and the dramatic decrease of sequencing costs, DNA sequencing has been widely used in scientific research, diagnosis of and treatment selection for human diseases. However, due to the lack of effective quality assessment and control of the high-throughput omics data generation and analysis processes, variants calling results are seriously inconsistent among different technical replicates, batches, laboratories, sequencing platforms, and analysis pipelines, resulting in irreproducible scientific results and conclusions, huge waste of resources, and even endangering the life and health of patients. Therefore, reference materials for quality control of the whole process from omics data generation to data analysis are urgently needed. We first established genomic DNA reference materials from four immortalized B-lymphoblastoid cell lines of a Chinese Quartet family including parents and monozygotic twin daughters to make performance assessment of germline variants calling results. To establish small variant benchmark calls and regions, we generated whole-genome sequencing data in nine batches, with depth ranging from 30x to 60x, by employing PCR-free and PCR libraries on four popular short-read sequencing platforms (Illumina HiSeq XTen, Illumina NovaSeq, MGISEQ-2000, and DNBSEQ-T7) with three replicates at each batch, resulting in 108 libraries in total and 27 libraries for each Quartet DNA reference material. Then, we selected variants concordant in multiple call sets and in Mendelian consistency within Quartet family members as small variant benchmark calls, resulting in 4.2 million high-confidence variants (SNV and Indel) and 2.66 G high confidence genomic region, covering 87.8% of the human reference genome (GRCh38, chr1-22 and X). Two orthogonal technologies were used for verifying the high-confidence variants. The consistency rate with PMRA (Axiom Precision Medicine Research Array) was 99.6%, and 95.9% of high-confidence variants were validated by 10X Genomics whole-genome sequencing data. Genetic built-in truth of the Quartet family design is another kind of \u201ctruth\u201d within the four Quartet samples. Apart from comparison with benchmark calls in the benchmark regions to identify false-positive and false-negative variants, pedigree information among the Quartet DNA reference materials, i.e., reproducibility rate of variants between the twins and Mendelian concordance rate among family members, are complementary approaches to comprehensively estimate genome-wide variants calling performance. Finally, we developed a whole-genome sequencing data quality assessment pipeline and demonstrated its utilities with two examples of using the Quartet reference materials and datasets to evaluate data generation performance in three sequencing labs and different data analysis pipelines.","title":"Chinese Quartet DNA reference materials"},{"location":"data_pipelines/genomics/intro/#requirements-for-your-data-and-metadata","text":"Metadata Template - Download the metadata template and prepare your metabata Data Format - Follow the data format requirements to prepare your genomics data","title":"Requirements for your data and metadata"},{"location":"data_pipelines/genomics/intro/#analyze-your-data-on-quartet-data-portal","text":"See more details on Step by Step Guide","title":"Analyze your data on Quartet Data Portal"},{"location":"data_pipelines/genomics/intro/#analyze-your-data-on-your-own-server","text":"Quartet DSeQC Report is a quality assessment tool for WGS/WES data. It supports two format: Fastq and vcf . And it contains three subcommands: fq-workflow , vcf-workflow and report . The fq-workflow command takes raw reads (in FASTQ format), produces a set of qc result files from them (More details on DNA-Seq (WGS) QC for Quartet and DNA-Seq (WES) QC for Quartet ). When you have produced vcf files from your own pipeline, you can use the vcf-workflow command. It takes vcf files and produces a set of qc result files from them. After above processes, you can use report command to report the results finally (More details on QC Report for Quartet RNA-Seq ).","title":"Analyze your data on your own server"},{"location":"data_pipelines/genomics/intro/#if-you-have-raw-reads-in-fastq-format","text":"CAUTION The pipeline for raw reads depends on Sentieon software. So if you want to use the pipeline, you need to specify the license server by -S option. If you don't have the license, we recommend you analyze your data on Quartet Data Portal . If not, please contact Sentieon or use the vcf mode. If you have your own pipeline, you can use your own pipeline to produce vcf files from your raw reads. Then you can use the vcf-workflow command to analyze your data. More details at the following section. [STATEMENT: We don't have any relationship with Sentieon and don't get any benefit from Sentieon.] Assuming your data files are in the /your-dir directory. Prepare a set of subdirectories mkdir -p /your-dir/raw-data /your-dir/references /your-dir/results /your-dir/report Download the dependency files wget https://zenodo.org/record/7800049/files/quartet-dseqc-report-reference-data-v20230404.zip?download=1 unzip quartet-dseqc-report-reference-data-v20230404.zip # You need to place the reference files into /your-dir/references directory Place your data files into /your-dir/raw-data directory Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a Generate qc result files by workflow command # For WGS Fastq data ## Assume the following conditions: ### 1. Your file name is like: d5.R1.gz, d5.R2.gz, d6.R1.gz, d6.R2.gz, f7.R1.gz, f7.R2.gz, m8.R1.gz, m8.R2.gz ### 2. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103, GRCh38.d1.vd1 and fastq_screen_reference directories. [You can follow the step 1 to download the reference files.] ### 3. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 4. The pipeline depends on Sentieon software, you need to specify -S to set the license server. ### 5. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a fq-workflow --d5-r1 /data/raw-data/d5.R1.gz --d5-r2 /data/raw-data/d5.R2.gz --d6-r1 /data/raw-data/d6.R1.gz --d6-r2 /data/raw-data/d6.R2.gz --f7-r1 /data/raw-data/f7.R1.gz --f7-r2 /data/raw-data/f7.R2.gz --m8-r1 /data/raw-data/m8.R1.gz --m8-r2 /data/raw-data/m8.R2.gz -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 -F /data/references/fastq_screen_reference -S 192.168.1.1:8990 --output-dir /data/results # For WES Fastq data ## Assume the following conditions: ### 1. Your file name is like: d5.R1.gz, d5.R2.gz, d6.R1.gz, d6.R2.gz, f7.R1.gz, f7.R2.gz, m8.R1.gz, m8.R2.gz ### 2. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103, GRCh38.d1.vd1 and fastq_screen_reference directories. [You can follow the step 1 to download the reference files.] ### 3. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 4. The pipeline depends on Sentieon software, you need to specify -S to set the license server. ### 5. You need to prepare your bed file and set -b option. ### 6. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a fq-workflow --d5-r1 /data/raw-data/d5.R1.gz --d5-r2 /data/raw-data/d5.R2.gz --d6-r1 /data/raw-data/d6.R1.gz --d6-r2 /data/raw-data/d6.R2.gz --f7-r1 /data/raw-data/f7.R1.gz --f7-r2 /data/raw-data/f7.R2.gz --m8-r1 /data/raw-data/m8.R1.gz --m8-r2 /data/raw-data/m8.R2.gz -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 -F /data/references/fastq_screen_reference -S 192.168.1.1:8990 --bed-file /data/references/your-bed-file --output-dir /data/results Report the results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a report -d /data/results --output-dir /data/report Find your QC report in /your-dir/report/multiqc_report.html","title":"If you have raw reads (in FASTQ format)"},{"location":"data_pipelines/genomics/intro/#if-you-have-vcf-files","text":"Assuming your data files are in the /your-dir directory. Prepare a set of subdirectories mkdir -p /your-dir/raw-data /your-dir/references /your-dir/results /your-dir/report Download the dependency files wget https://zenodo.org/record/7800049/files/quartet-dseqc-report-reference-data-v20230404.zip?download=1 unzip quartet-dseqc-report-reference-data-v20230404.zip # You need to place the reference files into /your-dir/references directory Place your data files into /your-dir/raw-data directory Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a Generate qc result files by workflow command # For WGS data ## Assume the following conditions: ### 1. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103 and GRCh38.d1.vd1 directories. [You can follow the step 1 to download the reference files.] ### 2. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 3. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a vcf-workflow --vcf-d5 /data/raw-data/d5.vcf --vcf-d6 /data/raw-data/d6.vcf --vcf-f7 /data/raw-data/f7.vcf --vcf-m8 /data/raw-data/m8.vcf -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 --output-dir /data/results # For WES data ## Assume the following conditions: ### 1. All of your reference files are in the /your-dir/references directory, including reference_datasets_v202103 and GRCh38.d1.vd1 directories. [You can follow the step 1 to download the reference files.] ### 2. If your data is produced by BGI sequencing platform, you can use -p BGI to set the platform. otherwise -p ILLUMINA ### 3. You need to prepare your bed file and set -b option. ### 4. The output directory is /your-dir/results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a vcf-workflow --vcf-d5 /data/raw-data/d5.vcf --vcf-d6 /data/raw-data/d6.vcf --vcf-f7 /data/raw-data/f7.vcf --vcf-m8 /data/raw-data/m8.vcf -p BGI -B /data/references/reference_datasets_v202103 -R /data/references/GRCh38.d1.vd1 --bed-file /data/references/your-bed-file --output-dir /data/results Report the results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-dseqc-report:v0.2.3-7a49aa4a report -d /data/results --output-dir /data/report # Known issue: # Only support one uuid directory in /your-dir/results directory. # If you have multiple uuid directories in /your-dir/results directory, the report will be failed or messy. # We will fix this issue in the future. Find your QC report in /your-dir/report/multiqc_report.html","title":"If you have vcf files"},{"location":"data_pipelines/genomics/intro/#more-details-about-the-analysis-pipeline","text":"QC APP - WGS QC for Quartet QC APP - WES QC for Quartet","title":"More details about the analysis pipeline"},{"location":"data_pipelines/genomics/metadata_template/","text":"English or Chinese? English means With English Annotations ; Chinese means With Chinese Annotations ; Latest Version \u00b6 English Version - Recommended Chinese Version Previous Versions \u00b6 20221128 - English \u00b6 CHANGELOG: This is the first commit. 20221128 - Chinese \u00b6 CHANGELOG: This is the first commit.","title":"Metadata Template"},{"location":"data_pipelines/genomics/metadata_template/#latest-version","text":"English Version - Recommended Chinese Version","title":"Latest Version"},{"location":"data_pipelines/genomics/metadata_template/#previous-versions","text":"","title":"Previous Versions"},{"location":"data_pipelines/genomics/metadata_template/#20221128-english","text":"CHANGELOG: This is the first commit.","title":"20221128 - English"},{"location":"data_pipelines/genomics/metadata_template/#20221128-chinese","text":"CHANGELOG: This is the first commit.","title":"20221128 - Chinese"},{"location":"data_pipelines/genomics/omics_data_format/","text":"Omics Data Format \u00b6 The data format that can be analyzed online are: Pair-end FASTQ files, with suffixes of _R1.fastq.gz and _R2.fastq.gz or _R1.fq.gz and _R2.fq.gz. unzipped VCF files, with suffixes of .vcf . We suggest to standardize the file names of updated data files as follows: Quartet_Omics_SequencePlatform_SequenceMachine_LibraryPrep_SequenceSite_Sample_Replicate_Date_R1/R2.fastq/fq.gz Here are some examples of file names: Fastq read 1: Quartet_WGS_ILM_Nova_PCRfree_FD_D5_1_20230635_R1.fq.gz Fastq read 2: Quartet_WGS_ILM_Nova_PCRfree_FD_D5_1_20230635_R2.fq.gz VCF: Quartet_WGS_ILM_Nova_PCRfree_FD_D5_1_20230635.vcf Fields in the file name are explained as follows: Omics Omics type Character DNA WGS WGS DNA WES WES SequencePlatform Platform Character illumina ILM BGI BGI Pacbio Pacbio Nanopore ONT Please note that the table provides examples of commonly used representative sequencing platforms, rather than an exhaustive compilation of all exiting sequencing platforms. If you use sequencing platforms not listed in the table, please use 2 to 6 letters as abbreviations to represent the sequencing platforms. SequenceMachine Platform Machine Character illumina XTen XTen illumina Novasq Nova illumina Hiseq4000 Hiseq4000 illumina Hiseq2500 Hiseq2500 illumina 10x 10x BGI SEQ500 SEQ500 BGI SEQ2000 SEQ2000 BGI DNBSEQ-T7 T7 Pacbio Sequel Sequel Pacbio Sequel II Sequel2 Nanopore PromethION 24 P24 Nanopore MinION MinION Please note that the table provides examples of commonly used representative sequencing machines, rather than an exhaustive compilation of all exiting sequencing machines. If you use sequencing platforms not listed in the table, please use 2 to 6 letters as abbreviations to represent the sequencing machines. LibraryPrep LibraryPrep Character PCR PCR PCR-free PCRfree SequenceSite Please use a few uppercase letters as abbreviations to represent the sequence centers or labs. For example, Fudan to FD. Sample Sample Character Quartet-D5 D5 Quartet-D6 D6 Quartet-F7 F7 Quartet-M8 M8 Replicate If you sequenced multiple replicates for the same reference material, use numbers such as 1, 2, 3, ... to represent technical replicates. Date The format of Date is yyyymmdd. For example, June 25, 2023 shoud be written to 20230625. Note In addition, there is one thing to note when using the Quartet DNAseq APP. The \"Sample ID\" in the parameter setting page refers to the number of data sets (one technical replicate of each sample is considered as one set, i.e. D5-D6-F7-M8). For example, if you provide data for 8 samples, that means two sets of data, so fill in \"2\".","title":"Omics Data Format"},{"location":"data_pipelines/genomics/omics_data_format/#omics-data-format","text":"The data format that can be analyzed online are: Pair-end FASTQ files, with suffixes of _R1.fastq.gz and _R2.fastq.gz or _R1.fq.gz and _R2.fq.gz. unzipped VCF files, with suffixes of .vcf . We suggest to standardize the file names of updated data files as follows: Quartet_Omics_SequencePlatform_SequenceMachine_LibraryPrep_SequenceSite_Sample_Replicate_Date_R1/R2.fastq/fq.gz Here are some examples of file names: Fastq read 1: Quartet_WGS_ILM_Nova_PCRfree_FD_D5_1_20230635_R1.fq.gz Fastq read 2: Quartet_WGS_ILM_Nova_PCRfree_FD_D5_1_20230635_R2.fq.gz VCF: Quartet_WGS_ILM_Nova_PCRfree_FD_D5_1_20230635.vcf Fields in the file name are explained as follows: Omics Omics type Character DNA WGS WGS DNA WES WES SequencePlatform Platform Character illumina ILM BGI BGI Pacbio Pacbio Nanopore ONT Please note that the table provides examples of commonly used representative sequencing platforms, rather than an exhaustive compilation of all exiting sequencing platforms. If you use sequencing platforms not listed in the table, please use 2 to 6 letters as abbreviations to represent the sequencing platforms. SequenceMachine Platform Machine Character illumina XTen XTen illumina Novasq Nova illumina Hiseq4000 Hiseq4000 illumina Hiseq2500 Hiseq2500 illumina 10x 10x BGI SEQ500 SEQ500 BGI SEQ2000 SEQ2000 BGI DNBSEQ-T7 T7 Pacbio Sequel Sequel Pacbio Sequel II Sequel2 Nanopore PromethION 24 P24 Nanopore MinION MinION Please note that the table provides examples of commonly used representative sequencing machines, rather than an exhaustive compilation of all exiting sequencing machines. If you use sequencing platforms not listed in the table, please use 2 to 6 letters as abbreviations to represent the sequencing machines. LibraryPrep LibraryPrep Character PCR PCR PCR-free PCRfree SequenceSite Please use a few uppercase letters as abbreviations to represent the sequence centers or labs. For example, Fudan to FD. Sample Sample Character Quartet-D5 D5 Quartet-D6 D6 Quartet-F7 F7 Quartet-M8 M8 Replicate If you sequenced multiple replicates for the same reference material, use numbers such as 1, 2, 3, ... to represent technical replicates. Date The format of Date is yyyymmdd. For example, June 25, 2023 shoud be written to 20230625. Note In addition, there is one thing to note when using the Quartet DNAseq APP. The \"Sample ID\" in the parameter setting page refers to the number of data sets (one technical replicate of each sample is considered as one set, i.e. D5-D6-F7-M8). For example, if you provide data for 8 samples, that means two sets of data, so fill in \"2\".","title":"Omics Data Format"},{"location":"data_pipelines/genomics/qc_report/","text":"Comming Soon...","title":"Qc report"},{"location":"data_pipelines/metabolomics/qc_report/","text":"From Quantified Expression Profiles to QC Report for Metabolomics (targeted and untargeted) .csv format of quantified expression profiles at metabolite level Note You can find the source code on chinese-quartet/quartet-metqc-report Prepare data & metadata files \u00b6 Data File \u00b6 The data file provides quantitative information on Quartet samples at the metabolite level. 1. The data file should be comma separated values ( .csv ) or tab delimited text ( .txt ) with a header in the first row. Samples should be in the columns of the file. Quantitative results should be given in the form of concentrations or peak intensities and contain only numeric and positive values. Two columns accurately named \"metabolites\" and \"HMDBID\" are needed, which contain the name of the metabolite compound and HMDBID, respectively. If HMDBID is not available, use \"NA\" for missing values in the data file. Both sample or metabolite compound names must be unique and consist of a combination of common English letters, underscores and numbers for naming purpose. Sample name should not be started with numbers. Latin/Greek letters are not supported. More details on https://www.metaboanalyst.ca/docs/Format.xhtml . Metadata File \u00b6 The metadata file has the information of each sample in the data file. With columns accurately named \"col_names\" (names of samples, identical to their names in the columns of data file), \"strategy\" (Targeted or Untargeted), \"lab\" (the name of lab), \"sample\" (D5, D6, F7 and M8 for Quartet samples), \"rep\" (the replicates for each sample) and \"batch\" (the name of batch). A screenshot of a sample metadata table is shown below. Step by Step Guide \u00b6 Analyze your data on your own server \u00b6 Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-metqc-report:v0.2.1-3cc61071 Run quartet-metqc-report with docker image Assuming that your data file is named data.csv and metadata file is named metadata.csv and all files are placed in /your-dir directory. docker run -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-metqc-report:v0.2.1-3cc61071 -d /data/data.csv -m /data/metadata.csv -o /data Find your QC report in /your-dir/multiqc_report.html Analyze your data on Quartet Data Portal \u00b6 As for running the QC pipeline of metabolomics data, you can: 1) go to http://chinese-quartet.org/#/seq-flow/metqc-report-management ; 2) click the upper right button named \"New QC report\"; 3) click \"Step 1: Choose Report\", please choose \"QC Report for Quartet Metabolomics\" ; 4) click \"Step 2: Upload Files (s)\", please upload your data and metadata files (.csv). 5) click \"Step 3: Parameters & Submit\", please fill in the blanks and submit the job. See more details on Step by Step Guide","title":"QC Report"},{"location":"data_pipelines/metabolomics/qc_report/#prepare-data-metadata-files","text":"","title":"Prepare data &amp; metadata files"},{"location":"data_pipelines/metabolomics/qc_report/#data-file","text":"The data file provides quantitative information on Quartet samples at the metabolite level. 1. The data file should be comma separated values ( .csv ) or tab delimited text ( .txt ) with a header in the first row. Samples should be in the columns of the file. Quantitative results should be given in the form of concentrations or peak intensities and contain only numeric and positive values. Two columns accurately named \"metabolites\" and \"HMDBID\" are needed, which contain the name of the metabolite compound and HMDBID, respectively. If HMDBID is not available, use \"NA\" for missing values in the data file. Both sample or metabolite compound names must be unique and consist of a combination of common English letters, underscores and numbers for naming purpose. Sample name should not be started with numbers. Latin/Greek letters are not supported. More details on https://www.metaboanalyst.ca/docs/Format.xhtml .","title":"Data File"},{"location":"data_pipelines/metabolomics/qc_report/#metadata-file","text":"The metadata file has the information of each sample in the data file. With columns accurately named \"col_names\" (names of samples, identical to their names in the columns of data file), \"strategy\" (Targeted or Untargeted), \"lab\" (the name of lab), \"sample\" (D5, D6, F7 and M8 for Quartet samples), \"rep\" (the replicates for each sample) and \"batch\" (the name of batch). A screenshot of a sample metadata table is shown below.","title":"Metadata File"},{"location":"data_pipelines/metabolomics/qc_report/#step-by-step-guide","text":"","title":"Step by Step Guide"},{"location":"data_pipelines/metabolomics/qc_report/#analyze-your-data-on-your-own-server","text":"Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-metqc-report:v0.2.1-3cc61071 Run quartet-metqc-report with docker image Assuming that your data file is named data.csv and metadata file is named metadata.csv and all files are placed in /your-dir directory. docker run -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-metqc-report:v0.2.1-3cc61071 -d /data/data.csv -m /data/metadata.csv -o /data Find your QC report in /your-dir/multiqc_report.html","title":"Analyze your data on your own server"},{"location":"data_pipelines/metabolomics/qc_report/#analyze-your-data-on-quartet-data-portal","text":"As for running the QC pipeline of metabolomics data, you can: 1) go to http://chinese-quartet.org/#/seq-flow/metqc-report-management ; 2) click the upper right button named \"New QC report\"; 3) click \"Step 1: Choose Report\", please choose \"QC Report for Quartet Metabolomics\" ; 4) click \"Step 2: Upload Files (s)\", please upload your data and metadata files (.csv). 5) click \"Step 3: Parameters & Submit\", please fill in the blanks and submit the job. See more details on Step by Step Guide","title":"Analyze your data on Quartet Data Portal"},{"location":"data_pipelines/metabolomics/sharing_raw_data/","text":"To Upload Your Raw Data \u00b6 Purpose Only for Collecting Data, if you just want to generate QC report for your data, please go to QC Report Metadata File Template - Latest Version","title":"Sharing Raw Data"},{"location":"data_pipelines/metabolomics/sharing_raw_data/#to-upload-your-raw-data","text":"Purpose Only for Collecting Data, if you just want to generate QC report for your data, please go to QC Report Metadata File Template - Latest Version","title":"To Upload Your Raw Data"},{"location":"data_pipelines/proteomics/qc_report/","text":"From Quantified Expression Profiles to QC Report Note You can find the source code on chinese-quartet/quartet-protqc-report I. Prepare data & metadata files \u00b6 Data File \u00b6 The data file provides the quantified proteins that are mapped to gene symbols and quantified peptide sequences, and the missing values are allowed. The required file format has the columns named Type and Feature . Please ensure that there are no duplicated column names in the data file. If the type of features is Gene Symbol only, then the metric Relative Correlation with Reference Datasets (RC) will not be calculated. Please see the example of the required data file as follows. Data Template Metadata File \u00b6 The metadata file has the information of each sample ID in the data file. With columns named \"library\", \"sample\" (D5, D6, F7 and M8 for Quartet samples). Remember that the column \"library\" and column names of the data file table must be in one-to-one correspondence. If the sample type \"D6\" is missing, then the metric Relative Correlation with Reference Datasets (RC) will not be calculated. Please see the example of the required data file as follows. Metadata Template II. Step by Step Guide \u00b6 To analyze your data on Quartet Data Portal \u00b6 See details on Step by Step Guide To analyze your data on your own server \u00b6 Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-protqc-report:v0.2.4-6534a16b Run quartet-protqc-report with docker image Assuming that your data file is named data.csv and metadata file is named metadata.csv and all files are placed in /your-dir directory. docker run -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-protqc-report:v0.2.4-6534a16b -d /data/data.csv -m /data/metadata.csv -o /data Find your QC report in /your-dir/multiqc_report.html III. QC metrics \u00b6 The package protqc output Quality Control(QC) results of proteomics data for Quartet Project. The QC pipeline starts from the expression profiles at peptide/protein levels, and enables to calculate 6 metrics. A Total score is the geometric mean of the linearly normalized values of these metrics. Number of features : We expect as many proteins (mapped to gene symbols) as possible for downstreaming analyses. Identified proteins were filtered by the rule of 5% FDR. However, if you set stricter rules (e.g., 1% FDR), less number but high confidence of proteins will be retained (then your data may rank relatively low in terms of Number of features ). Missing percentage (%) : Too many missing values interfere with comparability. This metric is calculated globally. Coefficient of variantion (CV, %) : A CV value is calculated to indicate the dispersion within replicates feature by feature. Absolute Correlation : Pearson correlation reflects overall reproducibility within replicates. We calculate correlation coefficients between each two replicates within each biological sample (D5, D6, F7, M8), and take the median as the final value for absolute correlation. Signal-to-Noise Ratio (SNR) : SNR is established to characterize the ability of a platform or lab or batch, which is able to distinguish intrinsic differences among distinct biological sample groups (\u201csignal\u201d) from variations in technical replicates of the same sample group (\"noise\"). Relative Correlation with Reference Datasets (RC) : RC is used for assessment of quantitative consistency with the reference dataset at relative levels. For shotgun proteomics, quantitation at peptide levels is theoretically more reliable. Therefore, the reference dataset is established by benchmarking the relative expression values (log2FCs), for each peptide sequence of each sample pair (D5/D6, F7/D6, M8/D6), in historical datasets at peptide levels. We calculate relatively qualified (satisfied with thresholds of p < 0.05) log2FCs of the queried data, for overlapped peptides with the reference dataset, as the input for the assessment of quantitative consistency. Then RC value is Pearson correlation coefficient between the test dataset and the reference dataset.","title":"QC Report"},{"location":"data_pipelines/proteomics/qc_report/#i-prepare-data-metadata-files","text":"","title":"I. Prepare data &amp; metadata files"},{"location":"data_pipelines/proteomics/qc_report/#data-file","text":"The data file provides the quantified proteins that are mapped to gene symbols and quantified peptide sequences, and the missing values are allowed. The required file format has the columns named Type and Feature . Please ensure that there are no duplicated column names in the data file. If the type of features is Gene Symbol only, then the metric Relative Correlation with Reference Datasets (RC) will not be calculated. Please see the example of the required data file as follows. Data Template","title":"Data File"},{"location":"data_pipelines/proteomics/qc_report/#metadata-file","text":"The metadata file has the information of each sample ID in the data file. With columns named \"library\", \"sample\" (D5, D6, F7 and M8 for Quartet samples). Remember that the column \"library\" and column names of the data file table must be in one-to-one correspondence. If the sample type \"D6\" is missing, then the metric Relative Correlation with Reference Datasets (RC) will not be calculated. Please see the example of the required data file as follows. Metadata Template","title":"Metadata File"},{"location":"data_pipelines/proteomics/qc_report/#ii-step-by-step-guide","text":"","title":"II. Step by Step Guide"},{"location":"data_pipelines/proteomics/qc_report/#to-analyze-your-data-on-quartet-data-portal","text":"See details on Step by Step Guide","title":"To analyze your data on Quartet Data Portal"},{"location":"data_pipelines/proteomics/qc_report/#to-analyze-your-data-on-your-own-server","text":"Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-protqc-report:v0.2.4-6534a16b Run quartet-protqc-report with docker image Assuming that your data file is named data.csv and metadata file is named metadata.csv and all files are placed in /your-dir directory. docker run -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-protqc-report:v0.2.4-6534a16b -d /data/data.csv -m /data/metadata.csv -o /data Find your QC report in /your-dir/multiqc_report.html","title":"To analyze your data on your own server"},{"location":"data_pipelines/proteomics/qc_report/#iii-qc-metrics","text":"The package protqc output Quality Control(QC) results of proteomics data for Quartet Project. The QC pipeline starts from the expression profiles at peptide/protein levels, and enables to calculate 6 metrics. A Total score is the geometric mean of the linearly normalized values of these metrics. Number of features : We expect as many proteins (mapped to gene symbols) as possible for downstreaming analyses. Identified proteins were filtered by the rule of 5% FDR. However, if you set stricter rules (e.g., 1% FDR), less number but high confidence of proteins will be retained (then your data may rank relatively low in terms of Number of features ). Missing percentage (%) : Too many missing values interfere with comparability. This metric is calculated globally. Coefficient of variantion (CV, %) : A CV value is calculated to indicate the dispersion within replicates feature by feature. Absolute Correlation : Pearson correlation reflects overall reproducibility within replicates. We calculate correlation coefficients between each two replicates within each biological sample (D5, D6, F7, M8), and take the median as the final value for absolute correlation. Signal-to-Noise Ratio (SNR) : SNR is established to characterize the ability of a platform or lab or batch, which is able to distinguish intrinsic differences among distinct biological sample groups (\u201csignal\u201d) from variations in technical replicates of the same sample group (\"noise\"). Relative Correlation with Reference Datasets (RC) : RC is used for assessment of quantitative consistency with the reference dataset at relative levels. For shotgun proteomics, quantitation at peptide levels is theoretically more reliable. Therefore, the reference dataset is established by benchmarking the relative expression values (log2FCs), for each peptide sequence of each sample pair (D5/D6, F7/D6, M8/D6), in historical datasets at peptide levels. We calculate relatively qualified (satisfied with thresholds of p < 0.05) log2FCs of the queried data, for overlapped peptides with the reference dataset, as the input for the assessment of quantitative consistency. Then RC value is Pearson correlation coefficient between the test dataset and the reference dataset.","title":"III. QC metrics"},{"location":"data_pipelines/proteomics/sharing_raw_data/","text":"To Upload Your Raw Data \u00b6 Purpose Only for Collecting Data, if you just want to generate QC report for your data, please go to QC Report Metadata File Template - Latest Version","title":"Sharing Raw Data"},{"location":"data_pipelines/proteomics/sharing_raw_data/#to-upload-your-raw-data","text":"Purpose Only for Collecting Data, if you just want to generate QC report for your data, please go to QC Report Metadata File Template - Latest Version","title":"To Upload Your Raw Data"},{"location":"data_pipelines/transcriptomics/analysis_pipeline/","text":"RNAseq analysis pipeline \u00b6 Preliminary processing of raw fastq reads was performed using fastp v0.19.6 to remove adapter sequences 1 . Read alignment and quantification was conducted using HISAT v2.1, SAMtools v1.3.1, StringTie v1.3.4 and Ballgown v2.14.1 2 . Reference human genome build 38 and gene model from Ensembl were used for read mapping and gene quantification. log2 transformation was then conducted based on Fragments Per Kilobase of transcript per Million mapped reads (FPKM) values. To avoid infinite values, a value of 0.01 was added to the FPKM value of each gene before log2 transformation. Expression profiles based on detected genes were used for further analysis. A gene was considered detectable (expressed) in a biological group within a batch if \u2265 3 reads were mapped onto it in at least two of the three replicates. Quality control analysis of sequencing data at pre-alignment and post-alignment level was conducted using FastQC v0.11.5 3 , FastQ Screen v0.12.0 4 , Qualimap v2.0.0 5 , and MultiQC v1.8 6 . Results generated from this APP can be visualized by QDP report. Reference \u00b6 Chen, S., Zhou, Y., Chen, Y. & Gu, J. fastp: an ultra-fast all-in-one FASTQ preprocessor. J Bioinformatics 34, i884-i890 (2018). \u21a9 Pertea, M., Kim, D., Pertea, G.M., Leek, J.T. & Salzberg, S.L. Transcript-level expression analysis of RNA-seq experiments with HISAT, StringTie and Ballgown. Nat Protoc 11, 1650 (2016). \u21a9 Andrews, S. FastQC: a quality control tool for high throughput sequence data https://www.bioinformatics.babraham.ac.uk/projects/fastqc/. (2017). \u21a9 Wingett, S.W. & Andrews, S. FastQ Screen: A tool for multi-genome mapping and quality control. F1000Research 7 (2018). \u21a9 Garc\u00eda-Alcalde, F. et al. Qualimap: evaluating next-generation sequencing alignment data. Bioinformatics 28, 2678-2679 (2012). \u21a9 Ewels, P., Magnusson, M., Lundin, S. & K\u00e4ller, M. MultiQC: summarize analysis results for multiple tools and samples in a single report. Bioinformatics 32, 3047-3048 (2016). \u21a9","title":"Analysis Pipeline"},{"location":"data_pipelines/transcriptomics/analysis_pipeline/#rnaseq-analysis-pipeline","text":"Preliminary processing of raw fastq reads was performed using fastp v0.19.6 to remove adapter sequences 1 . Read alignment and quantification was conducted using HISAT v2.1, SAMtools v1.3.1, StringTie v1.3.4 and Ballgown v2.14.1 2 . Reference human genome build 38 and gene model from Ensembl were used for read mapping and gene quantification. log2 transformation was then conducted based on Fragments Per Kilobase of transcript per Million mapped reads (FPKM) values. To avoid infinite values, a value of 0.01 was added to the FPKM value of each gene before log2 transformation. Expression profiles based on detected genes were used for further analysis. A gene was considered detectable (expressed) in a biological group within a batch if \u2265 3 reads were mapped onto it in at least two of the three replicates. Quality control analysis of sequencing data at pre-alignment and post-alignment level was conducted using FastQC v0.11.5 3 , FastQ Screen v0.12.0 4 , Qualimap v2.0.0 5 , and MultiQC v1.8 6 . Results generated from this APP can be visualized by QDP report.","title":"RNAseq analysis pipeline"},{"location":"data_pipelines/transcriptomics/analysis_pipeline/#reference","text":"Chen, S., Zhou, Y., Chen, Y. & Gu, J. fastp: an ultra-fast all-in-one FASTQ preprocessor. J Bioinformatics 34, i884-i890 (2018). \u21a9 Pertea, M., Kim, D., Pertea, G.M., Leek, J.T. & Salzberg, S.L. Transcript-level expression analysis of RNA-seq experiments with HISAT, StringTie and Ballgown. Nat Protoc 11, 1650 (2016). \u21a9 Andrews, S. FastQC: a quality control tool for high throughput sequence data https://www.bioinformatics.babraham.ac.uk/projects/fastqc/. (2017). \u21a9 Wingett, S.W. & Andrews, S. FastQ Screen: A tool for multi-genome mapping and quality control. F1000Research 7 (2018). \u21a9 Garc\u00eda-Alcalde, F. et al. Qualimap: evaluating next-generation sequencing alignment data. Bioinformatics 28, 2678-2679 (2012). \u21a9 Ewels, P., Magnusson, M., Lundin, S. & K\u00e4ller, M. MultiQC: summarize analysis results for multiple tools and samples in a single report. Bioinformatics 32, 3047-3048 (2016). \u21a9","title":"Reference"},{"location":"data_pipelines/transcriptomics/intro/","text":"Requirements for your data and metadata \u00b6 Metadata Template - Download the metadata template and prepare your metabata Data Format - Follow the data format requirements to prepare your genomics data Analyze your data on Quartet Data Portal \u00b6 See more details on Step by Step Guide Analyze your data on your own server \u00b6 Quartet RSeQC Report is a quality assessment tool for RNA-seq data. It contains two subcommands: workflow and report . The workflow command takes raw reads (in FASTQ format), produces a set of qc result files from them (More details on RNA-Seq QC for Quartet ). and you can use report command to report the results finally (More details on QC Report for Quartet RNA-Seq ). Assuming your data files are in the /your-dir directory. Prepare a set of subdirectories mkdir -p /your-dir/fastq_screen /your-dir/hisat2 /your-dir/gtf /your-dir/results /your-dir/raw-data /your-dir/report Download the dependency files # 1. Download reference genomes for `fastq_screen` (More details on https://figshare.com/articles/online_resource/fastq_screen_zip/22121078) wget https://figshare.com/ndownloader/files/39310673 -O /your-dir/fastq_screen/fastq_screen.zip unzip /your-dir/fastq_screen/fastq_screen.zip -d /your-dir/fastq_screen # 2. Download GTF file (More details on https://figshare.com/articles/online_resource/Homo_sapiens_GRCh38_93_gtf/22117475) wget https://figshare.com/ndownloader/files/39308702 -O /your-dir/gtf/Homo_sapiens.GRCh38.93.gtf # 3. Download Hisat2 index files (More details on https://figshare.com/articles/online_resource/hisat2_zip/22120538) wget https://figshare.com/ndownloader/files/39310418 -O /your-dir/hisat2/hisat2.zip unzip /your-dir/hisat2/hisat2.zip -d /your-dir/hisat2 Place your data files into /your-dir/raw-data directory Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.4-15cd635b Generate qc result files by workflow command docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.4-15cd635b workflow -i /data/hisat2 -g /data/gtf/gencode.v36.annotation.gtf -s /data/fastq_screen/fastq_screen.conf --output-dir /data/results --r1 /data/raw-data/example_R1.fq.gz --r2 /data/raw-data/example_R2.fq.gz Report the results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.4-15cd635b report -d /data/results -m /data/metadata.csv --output-dir /data/report Find your QC report in /your-dir/multiqc_report.html","title":"Introduction"},{"location":"data_pipelines/transcriptomics/intro/#requirements-for-your-data-and-metadata","text":"Metadata Template - Download the metadata template and prepare your metabata Data Format - Follow the data format requirements to prepare your genomics data","title":"Requirements for your data and metadata"},{"location":"data_pipelines/transcriptomics/intro/#analyze-your-data-on-quartet-data-portal","text":"See more details on Step by Step Guide","title":"Analyze your data on Quartet Data Portal"},{"location":"data_pipelines/transcriptomics/intro/#analyze-your-data-on-your-own-server","text":"Quartet RSeQC Report is a quality assessment tool for RNA-seq data. It contains two subcommands: workflow and report . The workflow command takes raw reads (in FASTQ format), produces a set of qc result files from them (More details on RNA-Seq QC for Quartet ). and you can use report command to report the results finally (More details on QC Report for Quartet RNA-Seq ). Assuming your data files are in the /your-dir directory. Prepare a set of subdirectories mkdir -p /your-dir/fastq_screen /your-dir/hisat2 /your-dir/gtf /your-dir/results /your-dir/raw-data /your-dir/report Download the dependency files # 1. Download reference genomes for `fastq_screen` (More details on https://figshare.com/articles/online_resource/fastq_screen_zip/22121078) wget https://figshare.com/ndownloader/files/39310673 -O /your-dir/fastq_screen/fastq_screen.zip unzip /your-dir/fastq_screen/fastq_screen.zip -d /your-dir/fastq_screen # 2. Download GTF file (More details on https://figshare.com/articles/online_resource/Homo_sapiens_GRCh38_93_gtf/22117475) wget https://figshare.com/ndownloader/files/39308702 -O /your-dir/gtf/Homo_sapiens.GRCh38.93.gtf # 3. Download Hisat2 index files (More details on https://figshare.com/articles/online_resource/hisat2_zip/22120538) wget https://figshare.com/ndownloader/files/39310418 -O /your-dir/hisat2/hisat2.zip unzip /your-dir/hisat2/hisat2.zip -d /your-dir/hisat2 Place your data files into /your-dir/raw-data directory Pull docker image More versions on Docker Registry docker pull ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.4-15cd635b Generate qc result files by workflow command docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.4-15cd635b workflow -i /data/hisat2 -g /data/gtf/gencode.v36.annotation.gtf -s /data/fastq_screen/fastq_screen.conf --output-dir /data/results --r1 /data/raw-data/example_R1.fq.gz --r2 /data/raw-data/example_R2.fq.gz Report the results docker run -d -v /your-dir:/data -it ghcr.io/chinese-quartet/quartet-rseqc-report:v0.2.4-15cd635b report -d /data/results -m /data/metadata.csv --output-dir /data/report Find your QC report in /your-dir/multiqc_report.html","title":"Analyze your data on your own server"},{"location":"data_pipelines/transcriptomics/metadata_template/","text":"English or Chinese? English means With English Annotations ; Chinese means With Chinese Annotations ; Latest Version \u00b6 English Version - Recommended Chinese Version Previous Versions \u00b6 2022051201 - English \u00b6 CHANGELOG: This is the first commit. 2022051201 - Chinese \u00b6 CHANGELOG: This is the first commit.","title":"Metadata Template"},{"location":"data_pipelines/transcriptomics/metadata_template/#latest-version","text":"English Version - Recommended Chinese Version","title":"Latest Version"},{"location":"data_pipelines/transcriptomics/metadata_template/#previous-versions","text":"","title":"Previous Versions"},{"location":"data_pipelines/transcriptomics/metadata_template/#2022051201-english","text":"CHANGELOG: This is the first commit.","title":"2022051201 - English"},{"location":"data_pipelines/transcriptomics/metadata_template/#2022051201-chinese","text":"CHANGELOG: This is the first commit.","title":"2022051201 - Chinese"},{"location":"data_pipelines/transcriptomics/omics_data_format/","text":"RNA-Seq \u00b6 The data format that can be analysed online are pair-end FASTQ files, with suffixes of _R1.fastq.gz and _R2.fastq.gz or _R1.fq.gz and _R2.fq.gz . Your dataset must contain four groups D5, D6, F7 and M8, with at least 2 technical replicates in each group. The reason is as follows. In order to be able to compare with our reference dataset constructed based on the four groups D5, D6, F7 and M8, your dataset must contain D5, D6, F7 and M8. The SNR is calculated based on the ratio of signal (between the four groups) to noise (technical replicates within the group), so each group contains at least two technical replicates. Note In addition, there is one thing to note when using the Quartet RNAseq APP. The \"Sample ID\" in the parameter setting page refers to the number of samples. For example, if your data contains 8 samples(such as D5, D6, F7 and M8 * 2 technical replicates), you should fill in \"8\". miRNAseq \u00b6 We haven't developed the analysis pipeline.","title":"Omics Data Format"},{"location":"data_pipelines/transcriptomics/omics_data_format/#rna-seq","text":"The data format that can be analysed online are pair-end FASTQ files, with suffixes of _R1.fastq.gz and _R2.fastq.gz or _R1.fq.gz and _R2.fq.gz . Your dataset must contain four groups D5, D6, F7 and M8, with at least 2 technical replicates in each group. The reason is as follows. In order to be able to compare with our reference dataset constructed based on the four groups D5, D6, F7 and M8, your dataset must contain D5, D6, F7 and M8. The SNR is calculated based on the ratio of signal (between the four groups) to noise (technical replicates within the group), so each group contains at least two technical replicates. Note In addition, there is one thing to note when using the Quartet RNAseq APP. The \"Sample ID\" in the parameter setting page refers to the number of samples. For example, if your data contains 8 samples(such as D5, D6, F7 and M8 * 2 technical replicates), you should fill in \"8\".","title":"RNA-Seq"},{"location":"data_pipelines/transcriptomics/omics_data_format/#mirnaseq","text":"We haven't developed the analysis pipeline.","title":"miRNAseq"},{"location":"data_pipelines/transcriptomics/qc_report/","text":"Quality Metrics \u00b6 Metric Description Range v1 Cutoff v1 Signal-to-Noise Ratio (SNR) Based on the Quartet design, a Signal-to-Noise Ratio (SNR) metric was established to gauge the performance of a platform, a lab, a protocol, or a batch in distinguishing the intrinsic biological differences (\u201csignal\u201d) among the Quartet samples from variations among technical replicates of the same sample group (\u201cnoise\u201d). Generally, a lower SNR value indicates lower discriminating power, vice versa. For an SNR value around or below zero, it means that the magnitude of signal is at a similar level as the noise or even lower than the noise. In this case, it is almost impossible to distinguish different sample groups under the high level of technical noises. Here, we used the first two principal components for calculating SNR, in correspondence with visualization in commonly used two-dimensional PCA plots. (-\u221e, +\u221e) >12 Relative correlation with reference datasets (RC) Relative correlation with reference datasets was calculated based on the Pearson correlation coefficient between the ratio-based expression levels of a dataset for a given pair of groups and the corresponding ratio-based reference datasets, representing the trend of numerical consistency of the ratio-based expression profiles. Reference datasets were pre-defined datasets in the format of a geometric mean by summarizing from the fold-changes calculated from the high-quality RNAseq datasets, providing \u201cground truth\u201d for benchmarking. [-1, 1] >0.89 Total score The total performance score is calculated to measure the overall quality of a dataset generated from a lab for its effectiveness in quantifying the transcriptomic differences among the four Quartet RNA reference materials by summarizing reference dataset-independent quality measurement (SNR) and reference dataset-dependent quality measurement (RC). The total score is expressed as the geometrical mean of SNR and RC. (-\u221e, +\u221e) Raw Data Quality & Mapping Quality \u00b6 Quality Metrics Software Description Reference Value Total.Sequences Fastqc - > 10 M GC_beforemapping Fastqc - 40% - 60% total_deduplicated_percentage Fastqc - Human.percentage FastQ Screen - > 90 % ERCC.percentage FastQ Screen - < 5% EColi.percentage FastQ Screen - < 5% Adapter.percentage FastQ Screen - < 5% Vector.percentage FastQ Screen - < 5% rRNA.percentage FastQ Screen - < 10% Virus.percentage FastQ Screen - < 5% Yeast.percentage FastQ Screen - < 5% Mitoch.percentage FastQ Screen - < 5% Phix.percentage FastQ Screen - < 5% No.hits.percentage FastQ Screen - < 5% percentage_aligned_beforemapping Qualimap - > 90% error_rate Qualimap - < 5% bias_53 Qualimap - GC_aftermapping Qualimap - 40% - 60% percent_duplicates Qualimap - sequence_length Qualimap - ~150 median_insert_size Qualimap - 200 - 300 mean_coverage Qualimap - ins_size_median Qualimap - 200 - 300 ins_size_peak Qualimap - 200 - 300 exonic Qualimap - 40% - 60% intronic Qualimap - 40% - 60% intergenic Qualimap - < 10%","title":"QC Report"},{"location":"data_pipelines/transcriptomics/qc_report/#quality-metrics","text":"Metric Description Range v1 Cutoff v1 Signal-to-Noise Ratio (SNR) Based on the Quartet design, a Signal-to-Noise Ratio (SNR) metric was established to gauge the performance of a platform, a lab, a protocol, or a batch in distinguishing the intrinsic biological differences (\u201csignal\u201d) among the Quartet samples from variations among technical replicates of the same sample group (\u201cnoise\u201d). Generally, a lower SNR value indicates lower discriminating power, vice versa. For an SNR value around or below zero, it means that the magnitude of signal is at a similar level as the noise or even lower than the noise. In this case, it is almost impossible to distinguish different sample groups under the high level of technical noises. Here, we used the first two principal components for calculating SNR, in correspondence with visualization in commonly used two-dimensional PCA plots. (-\u221e, +\u221e) >12 Relative correlation with reference datasets (RC) Relative correlation with reference datasets was calculated based on the Pearson correlation coefficient between the ratio-based expression levels of a dataset for a given pair of groups and the corresponding ratio-based reference datasets, representing the trend of numerical consistency of the ratio-based expression profiles. Reference datasets were pre-defined datasets in the format of a geometric mean by summarizing from the fold-changes calculated from the high-quality RNAseq datasets, providing \u201cground truth\u201d for benchmarking. [-1, 1] >0.89 Total score The total performance score is calculated to measure the overall quality of a dataset generated from a lab for its effectiveness in quantifying the transcriptomic differences among the four Quartet RNA reference materials by summarizing reference dataset-independent quality measurement (SNR) and reference dataset-dependent quality measurement (RC). The total score is expressed as the geometrical mean of SNR and RC. (-\u221e, +\u221e)","title":"Quality Metrics"},{"location":"data_pipelines/transcriptomics/qc_report/#raw-data-quality-mapping-quality","text":"Quality Metrics Software Description Reference Value Total.Sequences Fastqc - > 10 M GC_beforemapping Fastqc - 40% - 60% total_deduplicated_percentage Fastqc - Human.percentage FastQ Screen - > 90 % ERCC.percentage FastQ Screen - < 5% EColi.percentage FastQ Screen - < 5% Adapter.percentage FastQ Screen - < 5% Vector.percentage FastQ Screen - < 5% rRNA.percentage FastQ Screen - < 10% Virus.percentage FastQ Screen - < 5% Yeast.percentage FastQ Screen - < 5% Mitoch.percentage FastQ Screen - < 5% Phix.percentage FastQ Screen - < 5% No.hits.percentage FastQ Screen - < 5% percentage_aligned_beforemapping Qualimap - > 90% error_rate Qualimap - < 5% bias_53 Qualimap - GC_aftermapping Qualimap - 40% - 60% percent_duplicates Qualimap - sequence_length Qualimap - ~150 median_insert_size Qualimap - 200 - 300 mean_coverage Qualimap - ins_size_median Qualimap - 200 - 300 ins_size_peak Qualimap - 200 - 300 exonic Qualimap - 40% - 60% intronic Qualimap - 40% - 60% intergenic Qualimap - < 10%","title":"Raw Data Quality &amp; Mapping Quality"},{"location":"developers/changelog/","text":"News \u00b6 April 15, 2022 \u00b6 Improved the performance quartet-studio : opening time of the first screen is from 5-6 seconds to 1-2 seconds. Removed unused components. Minimize the image size. Split the js library to several chunks. April 10, 2022 \u00b6 Release a new version of quartet-studio","title":"Changelog"},{"location":"developers/changelog/#news","text":"","title":"News"},{"location":"developers/changelog/#april-15-2022","text":"Improved the performance quartet-studio : opening time of the first screen is from 5-6 seconds to 1-2 seconds. Removed unused components. Minimize the image size. Split the js library to several chunks.","title":"April 15, 2022"},{"location":"developers/changelog/#april-10-2022","text":"Release a new version of quartet-studio","title":"April 10, 2022"},{"location":"getting_started/analysis_history/","text":"Comming Soon...","title":"Analysis history"},{"location":"getting_started/browser_and_download/","text":"Comming Soon...","title":"Browser and download"},{"location":"getting_started/interactive_visualization/","text":"Comming Soon...","title":"Interactive visualization"},{"location":"getting_started/introduction/","text":"What is the Quartet Project? Quality Control and Data Integration of Multi-omics Profiling Multi-omics (or molecular phenomics) profiling at the genomic, transcriptomic, proteomic, and metabolomic levels is the cornerstone of high-throughput technologies for discovering biomarkers for precision medicine. However, the lack of quality control procedures of multi-omics profiling during data generation and data analysis can lead to false findings, raising serious concerns about the reliability of multi-omics studies. The Quartet Project provides publicly accessible multi-omics reference materials and practical tools to enhance the reproducibility and reliability of multi-omics results. Well-characterized multi-omics reference materials and quality control metrics pertinent to precision medicine study purposes can be used to measure and mitigate technical variation, enabling more accurate cross-batch and cross-omics data integration in increasingly large-scale and longitudinal studies such as the International Human Phenome Project. What is the Quartet Data Portal? \u00b6","title":"Overview"},{"location":"getting_started/introduction/#what-is-the-quartet-data-portal","text":"","title":"What is the Quartet Data Portal?"},{"location":"getting_started/qc_report/","text":"Comming Soon...","title":"Qc report"},{"location":"getting_started/quality_assessment_page/","text":"Comming Soon...","title":"Quality assessment page"},{"location":"getting_started/register_account/","text":"Policy for account registration \u00b6 If you want to upload your data to the platform and use the pipelines in the platform to analyze your data, you need to register an account. Otherwise, you can access the Quartet Data Portal as a guest (such as reference materials , omics data and other funtions). More details on the policy can be found in the document . Request Reference Materials and register an account \u00b6 You can access the Quartet Data Portal and request reference materials as a guest. We will receive the notification email after you submit a request for the reference materials. Our staff will contact you for further confirming your information and request (such as your organization, delivery address, required reference materials and quantity, purpose etc.). If we agree to the application, we will sent you a registration email and delivery the reference materials to you. Once you have registered, please go back to the home page (https://chinese-quartet.org) to log in. I have the Quartet reference materials but no account \u00b6 You can send an email to quartet@fudan.edu.cn for requesting an account (please let us know your name, organization, purpose etc.). After getting your request, our staff will contact you for further confirming your information and request (such as your organization, purpose etc.). If we agree to the application, we will sent you a registration email to you. Once you have registered, please go back to the home page (https://chinese-quartet.org) to log in.","title":"Register Account"},{"location":"getting_started/register_account/#policy-for-account-registration","text":"If you want to upload your data to the platform and use the pipelines in the platform to analyze your data, you need to register an account. Otherwise, you can access the Quartet Data Portal as a guest (such as reference materials , omics data and other funtions). More details on the policy can be found in the document .","title":"Policy for account registration"},{"location":"getting_started/register_account/#request-reference-materials-and-register-an-account","text":"You can access the Quartet Data Portal and request reference materials as a guest. We will receive the notification email after you submit a request for the reference materials. Our staff will contact you for further confirming your information and request (such as your organization, delivery address, required reference materials and quantity, purpose etc.). If we agree to the application, we will sent you a registration email and delivery the reference materials to you. Once you have registered, please go back to the home page (https://chinese-quartet.org) to log in.","title":"Request Reference Materials and register an account"},{"location":"getting_started/register_account/#i-have-the-quartet-reference-materials-but-no-account","text":"You can send an email to quartet@fudan.edu.cn for requesting an account (please let us know your name, organization, purpose etc.). After getting your request, our staff will contact you for further confirming your information and request (such as your organization, purpose etc.). If we agree to the application, we will sent you a registration email to you. Once you have registered, please go back to the home page (https://chinese-quartet.org) to log in.","title":"I have the Quartet reference materials but no account"},{"location":"getting_started/request_omics_data/","text":"1. Data Policies \u00b6 The Quartet Multi-omics reference materials and raw datasets are publicly available and accessible. Researchers are encouraged to access and analyze the datasets. The recipients of the Reference Materials are highly encouraged to share their data with Fudan University through the Quartet Data Portal in order for us to improve the reference datasets and to better serve the community. More details on the data policies can be found in the document . 2. How to bulk download the omics data files with browser? \u00b6 Filter and select your expected files Add them into file cart Go to file cart by clicking Cart Files button Click Download Files to downloading all files in cart. 3. How to bulk download the omics data files with file transfer tool? \u00b6 Download a metadata table from multi-omics data page.(such as genomics data in Multiomics Data -> Genomics Data ) Get the md5sum of files which you want to download from the metadata table. Follow the following docs to download your expected files. 3.1 Download file transfer tool - biominer-aget \u00b6 Click the link to download BioMiner Aget : Linux (CentOS, Debian/Ubuntu or Others) Mac (Intel, not m1 & m2 version) Mac ARM64 Windows Copy the biominer-aget_xxx binary into /usr/bin/biominer-aget_xxx or any other directory which in PATH variable. Note The chunk_size and concurrency parameters are related with the download speed. There may be tens or hundreds of times the difference, so it's worth taking some time to find the best one. Not each file can be found in all these repos, so you need to specify a repo name when you downloading expected file. 3.2 Download a data file with biominer-aget \u00b6 e.g. you want to download the file with UUID 0023a688-6569-44d7-a2cf-b031f4af8cdd or Hash (such as md5sum, sha128...) d4e50c8edbf5215fbe2afa1540f7c968 from the repository biominer.fudan-pgx, you can run the following command: For Mac (Intel) Users \u00b6 biominer-aget-x86_64-mac --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --output-dir ~/Downloads/ --repo http --chunk_size 1m --concurrency 1000 ## or biominer-aget-x86_64-mac --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo http --chunk_size 1m --concurrency 1000 ## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it. biominer-aget-x86_64-mac --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo node For Linux Users \u00b6 biominer-aget-x86_64-linux --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --output-dir ~/Downloads/ --repo gsa --chunk_size 1m --concurrency 1000 ## or biominer-aget-x86_64-linux --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo http --chunk_size 1m --concurrency 1000 ## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it. biominer-aget-x86_64-linux --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo node For Windows Users \u00b6 If you download the biominer-aget_xxx binary into C://Users/xxx/Desktop, you can use the following command to download data file from QDP. cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget-x86_64-windows --hash d4e50c8edbf5215fbe2afa1540f7c968 --repo http ## or cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget-x86_64-windows --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --repo http --chunk_size 1m --concurrency 1000 ## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it. cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget-x86_64-windows --hash d4e50c8edbf5215fbe2afa1540f7c968 --repo node $ biominer-aget --help Biominer Aget 0 .3.7 Jingcheng Yang <yjcyxky@163.com> An Index Engine for Omics Data Files USAGE: biominer-aget [ FLAGS ] [ OPTIONS ] FLAGS: -D, --debug Activate debug mode -h, --help Prints help information -V, --version Prints version information OPTIONS: -a, --api-server <api-server> The api server address -k, --chunk_size <chunk_size> The number of interval length of each concurrent request [ default: '50m' ] -c, --concurrency <concurrency> The number of concurrency request [ default: 10 ] --dns-timeout <dns-timeout> DNS Timeout ( seconds ) of request [ default: 10 ] -g, --guid <guid> The guid of the file you want to download, e.g. biominer.fudan-pgx/00006134-c655- 4bbe-9144-0ee86da83902 -H, --hash <hash> The hash of the file you want to download, e.g. b47ee06cdf62847f6d4c11bb12ac1ae0 -o, --output-dir <output-dir> Output directory [ default: ./ ] -p, --password <password> Password for the biominer api server [ default: anonymous ] -r, --repo <repo> Which data repository you want to download from [ default: node ] [ possible values: node, gsa, s3, oss, minio, http ] --retries <retries> The maximum times of retring [ default: 0 ] --retry-wait <retry-wait> The seconds between retries [ default: 0 ] -t, --timeout <timeout> Timeout ( seconds ) of request [ default: 60 ] -u, --username <username> Username for the biominer-indexd api server [ default: anonymous ] 4. How do you know a file is stored at which repo? \u00b6 Please access the BioMiner Indexd service and query file by md5sum, filename, or other metadata. When you find the record of a file, you can see more information as the following picture. In the picture, you can see the URLs field, it can tell you the file is stored at which repos. 5. Why BioMiner Indexd? \u00b6 We will release our data to multiple repos (such as NODE , GSA , SRA , ENA etc.), for your convenience, we provide the BioMiner Indexd service for aggregating all these repos. BioMiner Indexd is a hash-based data indexing and tracking service providing globally unique identifiers. 6. What multi-omics data do we provide? \u00b6 Genomics \u00b6 Quartet DNA reference materials have been extensively sequenced by short-read and long-read technologies. Short-read WGS datasets were generated with depth ranging from 30-60, by employing PCR-free and PCR libraries on multiple short-read sequencing platforms, including Illumina Hiseq XTen, Illumina Novaseq, MGISEQ-2000 and DNBSEQ-T7. We have sequenced 180 WGS libraries, 248 WES libraries in total. Long-read sequencing datasets have been generated using 10X genomics, Oxford Nanopore Technologies, BioNano Genomics, and Pacific Biosciences Sequel and Sequel II with CLR and CCS HiFi modes. Transcriptomics \u00b6 RNA-seq datasets from reference materials were then obtained, consisting of 252 RNA-seq libraries from 21 batches which were generated by eight laboratories using two library construction protocols (poly(A) selection and rRNA depletion) and two sequencing platforms (Illumina NovaSeq and BGI DNBseq). Here, a batch of RNA-seq experiments was defined as libraries from a standard sample set, consisting of 12 tubes with each representing one of the triplicates of the four RNA reference sample groups, which were conducted library construction and sequencing experiments concurrently. Proteomics \u00b6 Currently we sent 6 units of Quartet Protein Reference Materials to 6 labs, in which 6 batches of raw datasets and profiled datasets were generated in their in-house LC-MS/MS systems by label-free quantitation (both DDA and DIA). Our Cooperators also extracted human proteins (labeled as \u201cLot1\u201d in our metadata) from the immortalized B-lymphoblastoid cell lines and have generated 26 batches of DDA-based profiled datasets since 2017. Metabolomics \u00b6 We dispensed three biological replicates of each unit of the Quartet Metabolite Reference Materials to six laboratory platforms of five companies. These six laboratories produced a total of 204 metabolic quantitative profiles in 17 datasets (batches) using targeted or un-targeted metabolomics strategies. Furthermore, based on the large amount of copies of Quartet metabolite reference materials, we regularly generated targeted metabolomics data with three technical replicates for each unit of the Quartet Metabolite Reference Materials for up to one year in Metabo-Profile (L4).","title":"Access Quartet MultiOmics Data"},{"location":"getting_started/request_omics_data/#1-data-policies","text":"The Quartet Multi-omics reference materials and raw datasets are publicly available and accessible. Researchers are encouraged to access and analyze the datasets. The recipients of the Reference Materials are highly encouraged to share their data with Fudan University through the Quartet Data Portal in order for us to improve the reference datasets and to better serve the community. More details on the data policies can be found in the document .","title":"1. Data Policies"},{"location":"getting_started/request_omics_data/#2-how-to-bulk-download-the-omics-data-files-with-browser","text":"Filter and select your expected files Add them into file cart Go to file cart by clicking Cart Files button Click Download Files to downloading all files in cart.","title":"2. How to bulk download the omics data files with browser?"},{"location":"getting_started/request_omics_data/#3-how-to-bulk-download-the-omics-data-files-with-file-transfer-tool","text":"Download a metadata table from multi-omics data page.(such as genomics data in Multiomics Data -> Genomics Data ) Get the md5sum of files which you want to download from the metadata table. Follow the following docs to download your expected files.","title":"3. How to bulk download the omics data files with file transfer tool?"},{"location":"getting_started/request_omics_data/#31-download-file-transfer-tool-biominer-aget","text":"Click the link to download BioMiner Aget : Linux (CentOS, Debian/Ubuntu or Others) Mac (Intel, not m1 & m2 version) Mac ARM64 Windows Copy the biominer-aget_xxx binary into /usr/bin/biominer-aget_xxx or any other directory which in PATH variable. Note The chunk_size and concurrency parameters are related with the download speed. There may be tens or hundreds of times the difference, so it's worth taking some time to find the best one. Not each file can be found in all these repos, so you need to specify a repo name when you downloading expected file.","title":"3.1 Download file transfer tool - biominer-aget"},{"location":"getting_started/request_omics_data/#32-download-a-data-file-with-biominer-aget","text":"e.g. you want to download the file with UUID 0023a688-6569-44d7-a2cf-b031f4af8cdd or Hash (such as md5sum, sha128...) d4e50c8edbf5215fbe2afa1540f7c968 from the repository biominer.fudan-pgx, you can run the following command:","title":"3.2 Download a data file with biominer-aget"},{"location":"getting_started/request_omics_data/#for-mac-intel-users","text":"biominer-aget-x86_64-mac --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --output-dir ~/Downloads/ --repo http --chunk_size 1m --concurrency 1000 ## or biominer-aget-x86_64-mac --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo http --chunk_size 1m --concurrency 1000 ## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it. biominer-aget-x86_64-mac --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo node","title":"For Mac (Intel) Users"},{"location":"getting_started/request_omics_data/#for-linux-users","text":"biominer-aget-x86_64-linux --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --output-dir ~/Downloads/ --repo gsa --chunk_size 1m --concurrency 1000 ## or biominer-aget-x86_64-linux --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo http --chunk_size 1m --concurrency 1000 ## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it. biominer-aget-x86_64-linux --hash d4e50c8edbf5215fbe2afa1540f7c968 --output-dir ~/Downloads/ --repo node","title":"For Linux Users"},{"location":"getting_started/request_omics_data/#for-windows-users","text":"If you download the biominer-aget_xxx binary into C://Users/xxx/Desktop, you can use the following command to download data file from QDP. cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget-x86_64-windows --hash d4e50c8edbf5215fbe2afa1540f7c968 --repo http ## or cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget-x86_64-windows --guid biominer.fudan-pgx/0023a688-6569-44d7-a2cf-b031f4af8cdd --repo http --chunk_size 1m --concurrency 1000 ## NODE repo doesn't support http range, so the --chunk_size and --concurrency arguments don't work for it. cmd /c C:\\Users\\xxx\\Desktop\\biominer-aget-x86_64-windows --hash d4e50c8edbf5215fbe2afa1540f7c968 --repo node $ biominer-aget --help Biominer Aget 0 .3.7 Jingcheng Yang <yjcyxky@163.com> An Index Engine for Omics Data Files USAGE: biominer-aget [ FLAGS ] [ OPTIONS ] FLAGS: -D, --debug Activate debug mode -h, --help Prints help information -V, --version Prints version information OPTIONS: -a, --api-server <api-server> The api server address -k, --chunk_size <chunk_size> The number of interval length of each concurrent request [ default: '50m' ] -c, --concurrency <concurrency> The number of concurrency request [ default: 10 ] --dns-timeout <dns-timeout> DNS Timeout ( seconds ) of request [ default: 10 ] -g, --guid <guid> The guid of the file you want to download, e.g. biominer.fudan-pgx/00006134-c655- 4bbe-9144-0ee86da83902 -H, --hash <hash> The hash of the file you want to download, e.g. b47ee06cdf62847f6d4c11bb12ac1ae0 -o, --output-dir <output-dir> Output directory [ default: ./ ] -p, --password <password> Password for the biominer api server [ default: anonymous ] -r, --repo <repo> Which data repository you want to download from [ default: node ] [ possible values: node, gsa, s3, oss, minio, http ] --retries <retries> The maximum times of retring [ default: 0 ] --retry-wait <retry-wait> The seconds between retries [ default: 0 ] -t, --timeout <timeout> Timeout ( seconds ) of request [ default: 60 ] -u, --username <username> Username for the biominer-indexd api server [ default: anonymous ]","title":"For Windows Users"},{"location":"getting_started/request_omics_data/#4-how-do-you-know-a-file-is-stored-at-which-repo","text":"Please access the BioMiner Indexd service and query file by md5sum, filename, or other metadata. When you find the record of a file, you can see more information as the following picture. In the picture, you can see the URLs field, it can tell you the file is stored at which repos.","title":"4. How do you know a file is stored at which repo?"},{"location":"getting_started/request_omics_data/#5-why-biominer-indexd","text":"We will release our data to multiple repos (such as NODE , GSA , SRA , ENA etc.), for your convenience, we provide the BioMiner Indexd service for aggregating all these repos. BioMiner Indexd is a hash-based data indexing and tracking service providing globally unique identifiers.","title":"5. Why BioMiner Indexd?"},{"location":"getting_started/request_omics_data/#6-what-multi-omics-data-do-we-provide","text":"","title":"6. What multi-omics data do we provide?"},{"location":"getting_started/request_omics_data/#genomics","text":"Quartet DNA reference materials have been extensively sequenced by short-read and long-read technologies. Short-read WGS datasets were generated with depth ranging from 30-60, by employing PCR-free and PCR libraries on multiple short-read sequencing platforms, including Illumina Hiseq XTen, Illumina Novaseq, MGISEQ-2000 and DNBSEQ-T7. We have sequenced 180 WGS libraries, 248 WES libraries in total. Long-read sequencing datasets have been generated using 10X genomics, Oxford Nanopore Technologies, BioNano Genomics, and Pacific Biosciences Sequel and Sequel II with CLR and CCS HiFi modes.","title":"Genomics"},{"location":"getting_started/request_omics_data/#transcriptomics","text":"RNA-seq datasets from reference materials were then obtained, consisting of 252 RNA-seq libraries from 21 batches which were generated by eight laboratories using two library construction protocols (poly(A) selection and rRNA depletion) and two sequencing platforms (Illumina NovaSeq and BGI DNBseq). Here, a batch of RNA-seq experiments was defined as libraries from a standard sample set, consisting of 12 tubes with each representing one of the triplicates of the four RNA reference sample groups, which were conducted library construction and sequencing experiments concurrently.","title":"Transcriptomics"},{"location":"getting_started/request_omics_data/#proteomics","text":"Currently we sent 6 units of Quartet Protein Reference Materials to 6 labs, in which 6 batches of raw datasets and profiled datasets were generated in their in-house LC-MS/MS systems by label-free quantitation (both DDA and DIA). Our Cooperators also extracted human proteins (labeled as \u201cLot1\u201d in our metadata) from the immortalized B-lymphoblastoid cell lines and have generated 26 batches of DDA-based profiled datasets since 2017.","title":"Proteomics"},{"location":"getting_started/request_omics_data/#metabolomics","text":"We dispensed three biological replicates of each unit of the Quartet Metabolite Reference Materials to six laboratory platforms of five companies. These six laboratories produced a total of 204 metabolic quantitative profiles in 17 datasets (batches) using targeted or un-targeted metabolomics strategies. Furthermore, based on the large amount of copies of Quartet metabolite reference materials, we regularly generated targeted metabolomics data with three technical replicates for each unit of the Quartet Metabolite Reference Materials for up to one year in Metabo-Profile (L4).","title":"Metabolomics"},{"location":"getting_started/request_reference_materials/","text":"If you want to request reference materials, you can access the Quartet Data Portal and request reference materials as a guest. As the following figure shows, you can click the Request xx Materials button to request related reference materials. After you enter the request page, you can follow the instructions to fill in the form and submit your request. We will review your request and contact you as soon as possible. More details on the reference materails policy can be found in the document .","title":"Request Reference Materials"},{"location":"getting_started/select_pipeline/","text":"Comming Soon...","title":"Select pipeline"},{"location":"getting_started/step_by_step_guide_dna/","text":"","title":"Quality Assessment for WGS"},{"location":"getting_started/step_by_step_guide_metabolite/","text":"","title":"Quality Assessment for Metabolomics"},{"location":"getting_started/step_by_step_guide_protein/","text":"","title":"Quality Assessment for Proteomics"},{"location":"getting_started/step_by_step_guide_rna/","text":"","title":"Quality Assessment for Transcriptomics"},{"location":"getting_started/submit_data/","text":"Data submission policy \u00b6 The Quartet Multi-omics reference materials and raw datasets are publicly available and accessible. Researchers are encouraged to access and analyze the datasets. The recipients of the Reference Materials are highly encouraged to share their data with Fudan University through Public data warehouse (Recommended, such as SRA, ENA, GSA etc.) or the Quartet Data Portal (for analyzing your data online) in order for us to improve the reference datasets and to better serve the community. More details on the policy can be found in the document . How to upload and analyze your data? \u00b6 For convenience, we provide a web-based data analysis platform for users to analyze their data. Users can upload their in-house omics data generated with the Quartet reference sample, select the specific pipeline and parameters, and obtain the analysis results and QC results, which can be managed by the Quartet Data Portal. So if you only want to analyze your data with Quartet pipelines online, you can upload your data to the Quartet Data Portal. Please follow the steps: 1) Create a dataset by clicking the 'Register & Upload Your Data' 2) Get your access key and secret by clicking 'New Token' button 3) Review the data specification before uploading files 4) Upload your omics data files and metadata files 5) Verify and confirm Uploaded files by clicking 'Check' button After you checking your data, you can choose the pipeline and parameters to analyze your data. Tools for uploading data \u00b6 OSS Utility or OSS Browser","title":"Submit Your Raw Omics Data"},{"location":"getting_started/submit_data/#data-submission-policy","text":"The Quartet Multi-omics reference materials and raw datasets are publicly available and accessible. Researchers are encouraged to access and analyze the datasets. The recipients of the Reference Materials are highly encouraged to share their data with Fudan University through Public data warehouse (Recommended, such as SRA, ENA, GSA etc.) or the Quartet Data Portal (for analyzing your data online) in order for us to improve the reference datasets and to better serve the community. More details on the policy can be found in the document .","title":"Data submission policy"},{"location":"getting_started/submit_data/#how-to-upload-and-analyze-your-data","text":"For convenience, we provide a web-based data analysis platform for users to analyze their data. Users can upload their in-house omics data generated with the Quartet reference sample, select the specific pipeline and parameters, and obtain the analysis results and QC results, which can be managed by the Quartet Data Portal. So if you only want to analyze your data with Quartet pipelines online, you can upload your data to the Quartet Data Portal. Please follow the steps: 1) Create a dataset by clicking the 'Register & Upload Your Data' 2) Get your access key and secret by clicking 'New Token' button 3) Review the data specification before uploading files 4) Upload your omics data files and metadata files 5) Verify and confirm Uploaded files by clicking 'Check' button After you checking your data, you can choose the pipeline and parameters to analyze your data.","title":"How to upload and analyze your data?"},{"location":"getting_started/submit_data/#tools-for-uploading-data","text":"OSS Utility or OSS Browser","title":"Tools for uploading data"},{"location":"getting_started/toolbars/","text":"Comming Soon...","title":"Toolbars"},{"location":"policies/account_registration_policy/","text":"If you want to use the pipelines in the platform to analyze your data or submit your data to the platform, you need to register an account. The account registration policy is as follows: The account registration is free. The account registration is open to all users who are interested in the platform and agree to abide by the rules of the platform. You need to contact the administrator to register an account. Please provide your name, affiliation, purpose and email address (as the username) in the email. After the administrator approves your application, you will receive an email with registration link. You can use the link to set your password and login to the platform. we will reply to you within 3-7 working days. The administrator reserves the right to reject the following applications: The application is not from a valid email address (personal email address is not allowed). The application is not from a valid affiliation. The application is a commercial purpose (e.g. use the platform to provide services to others and charge fees). The administrator reserves the right to suspend or terminate the account if the user violates the following rules: The user uses the platform for commercial purposes. The user uses the platform to provide services to others. The user uses the platform to analyze data which is not generated with the quartet reference materials. The user uses the platform to conduct illegal activities. The user uses the platform to conduct activities that endanger the security of the platform. The user uses the platform to conduct activities that endanger the security of other users.","title":"Account Registration Policy"},{"location":"policies/data_request_policy/","text":"If you want to get all of data which are published on the platform, you don't need to register an account. Only need to access the download page , choose the data you want and download the metadata table which contains the md5sum of each data file. Then you can use the md5sum to download the data from the related data repositories. You can follow the tutorial to download the data. Or you can download the related data by clicking the download button on the data page. All data are free for all users for academic use. If you want to use the data for commercial purposes, please contact the administrator .","title":"Data Request Policy"},{"location":"policies/data_submission_policy/","text":"If you want to submit your data to the platform, you need to register an account. Then you can access the submit page to submit your data and metadata table. You can follow the tutorial to submit your data. The following is the data submission policy: Purpose \u00b6 The purpose of this policy is to establish guidelines for submitting data to ensure its integrity, accuracy, and consistency, while maintaining privacy and security. Scope \u00b6 This policy applies to all data submitted by internal and external parties. Submission Guidelines \u00b6 All data should be submitted in the requested format and within the specified metadata template. Genomics Data Submission Guidelines Transcriptomics Data Submission Guidelines Proteomics Data Submission Guidelines Metabolomics Data Submission Guidelines Data must be accurate, complete, and relevant. Data sources must be appropriately referenced. If you are submitting your data to a public repository, please provide the accession number in your metadata table. We strongly recommend that you submit your data to a public repository (e.g SRA, ENA, GSA etc.) and submit the metadata table to the platform. After getting the metadata table, we will check the data and metadata table. If there is no problem, we will publish the data on the platform and announce the uploader of the data on the data page. Personal and sensitive data must be anonymized or de-identified unless otherwise specified and agreed upon. If you are submitting data on behalf of an organization, you must have the authority to do so. Responsibility for Data Quality \u00b6 The individual or entity submitting the data is responsible for its quality, and must take appropriate steps to verify accuracy and completeness. The Quartet team reserves the right to review all data submissions for quality and compliance, and to reject submissions that fail to meet the established criteria or violate this policy. This policy may be revised periodically based on changes in legal, ethical, or technological contexts. All changes will be communicated to the relevant parties. Failure to comply with this policy may result in rejection of data, termination of data access, and potential legal action. Note: This policy must be understood and agreed upon before submitting data. For any questions, contact the Quartet Team","title":"Data Submission Policy"},{"location":"policies/data_submission_policy/#purpose","text":"The purpose of this policy is to establish guidelines for submitting data to ensure its integrity, accuracy, and consistency, while maintaining privacy and security.","title":"Purpose"},{"location":"policies/data_submission_policy/#scope","text":"This policy applies to all data submitted by internal and external parties.","title":"Scope"},{"location":"policies/data_submission_policy/#submission-guidelines","text":"All data should be submitted in the requested format and within the specified metadata template. Genomics Data Submission Guidelines Transcriptomics Data Submission Guidelines Proteomics Data Submission Guidelines Metabolomics Data Submission Guidelines Data must be accurate, complete, and relevant. Data sources must be appropriately referenced. If you are submitting your data to a public repository, please provide the accession number in your metadata table. We strongly recommend that you submit your data to a public repository (e.g SRA, ENA, GSA etc.) and submit the metadata table to the platform. After getting the metadata table, we will check the data and metadata table. If there is no problem, we will publish the data on the platform and announce the uploader of the data on the data page. Personal and sensitive data must be anonymized or de-identified unless otherwise specified and agreed upon. If you are submitting data on behalf of an organization, you must have the authority to do so.","title":"Submission Guidelines"},{"location":"policies/data_submission_policy/#responsibility-for-data-quality","text":"The individual or entity submitting the data is responsible for its quality, and must take appropriate steps to verify accuracy and completeness. The Quartet team reserves the right to review all data submissions for quality and compliance, and to reject submissions that fail to meet the established criteria or violate this policy. This policy may be revised periodically based on changes in legal, ethical, or technological contexts. All changes will be communicated to the relevant parties. Failure to comply with this policy may result in rejection of data, termination of data access, and potential legal action. Note: This policy must be understood and agreed upon before submitting data. For any questions, contact the Quartet Team","title":"Responsibility for Data Quality"},{"location":"policies/reference_materials_policy/","text":"CAUTION If you want to request reference materials, you don't need to register an account. Only need to access the request page , choose the materials you want and fill in the form. We will reply to you within 3-7 working days. If not received the confirmation email, please check the spam folder in your email box. If you have any questions, please contact the administrator . Please read the following terms and conditions: The reference materials are free for academic use. If you want to use the reference materials for commercial purposes, please contact the administrator . The Quartet team reserves the right to reject the following applications: Incomplete Applications: Applications that are incomplete or contain inaccurate information may be rejected. This includes failure to provide necessary documentation or provide required details.\u21b3 Non-Compliant Applications: Applications that do not adhere to Quartet's rules, regulations, or policies, as outlined in application instructions or Quartet's terms and conditions, may be rejected. Request unreasonable amount of reference materials. Request reference materials for commercial purposes, but not contact the administrator to discuss the details, get approval and sign the agreement. Don't agree to charge the necessary fees (such as shipping fees). Don't agree to provide the feedback about how to use the reference materials and the results of the analysis (It can be a publication, a poster, a presentation, or a report).","title":"Reference Materials Policy"},{"location":"roadmap/genomics/","text":"Mission \u00b6 Roadmap \u00b6 Task Category Description Status Plan Docs QDP Link Version First Version QC APP for WGS Quality control of germline variants calling results using a Chinese Quartet family (FastQ/VCF -> QC Results) Finished - README Access v0.2.0","title":"Genomics"},{"location":"roadmap/genomics/#mission","text":"","title":"Mission"},{"location":"roadmap/genomics/#roadmap","text":"Task Category Description Status Plan Docs QDP Link Version First Version QC APP for WGS Quality control of germline variants calling results using a Chinese Quartet family (FastQ/VCF -> QC Results) Finished - README Access v0.2.0","title":"Roadmap"},{"location":"roadmap/metabolomics/","text":"","title":"Metabolomics"},{"location":"roadmap/others/","text":"","title":"Others"},{"location":"roadmap/proteomics/","text":"","title":"Proteomics"},{"location":"roadmap/transcriptomics/","text":"","title":"Transcriptomics"},{"location":"tools/choppy_apps/","text":"Comming Soon...","title":"Choppy apps"},{"location":"tools/data_repo/","text":"Comming Soon...","title":"Data repo"},{"location":"tools/multireport/","text":"Comming Soon...","title":"Multireport"},{"location":"tools/ossbrowser/","text":"ossbrowser is a graphical management tool to upload data to the Quartet Data Portal. Name Recommendation Notice Category Characteristics Expected Average Speed OSS Browser Low Only use it when the total data volume is less than 100GB and the size of one single file is less than 5GB GUI Tool Easy, but slower than OSSUtil 1-30MB/s 1. Download and installation \u00b6 The ossbrowser supports the following operating systems: Windows, Linux, and macOS. You can download and install the ossbrowser version that best suits your requirements. Click here to download ossbrowser and see more details. 2. Log on to ossbrowser \u00b6 You will get the AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken), Preset Oss Path (uploadPath), and Auth-Token (authorizedCode) from data.json which is generated by clicking \"New Token\" button in Quartet Data portal website. The contents of the data.json file are as follows: { \"uploadPath\": \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\", \"region\": \"oss-cn-shanghai\", \"durationHours\": 12, \"expiration\": \"Thu Sep 23 2021 22:02:21 GMT+0800\", \"accessKey\": \"STS.NSw4TPayxZcbeXQbDfoZiHE16\", \"accessSecret\": \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\", \"stsToken\": \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\", \"authorizedCode\": \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\" } There are two methods to log on to ossbrowser, AK Login and Token Login. a. AK Login You need to fill in the AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken), and Preset Oss Path (uploadPath) as follows: b. Token Login You need to fill in the Auth-Token (authorizedCode) as follows: Then, you will see the following screen\uff1a 3. Click \"Upload\" to upload files \u00b6 You can click \"Upload\" button to upload your omics data files and metadata files, and then verify and confirm uploaded files by clicking \"Check\" button in Quartet Data portal website. You only have 12 duration hours, please upload as soon as possible.","title":"OSSBrowser"},{"location":"tools/ossbrowser/#1-download-and-installation","text":"The ossbrowser supports the following operating systems: Windows, Linux, and macOS. You can download and install the ossbrowser version that best suits your requirements. Click here to download ossbrowser and see more details.","title":"1. Download and installation"},{"location":"tools/ossbrowser/#2-log-on-to-ossbrowser","text":"You will get the AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken), Preset Oss Path (uploadPath), and Auth-Token (authorizedCode) from data.json which is generated by clicking \"New Token\" button in Quartet Data portal website. The contents of the data.json file are as follows: { \"uploadPath\": \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\", \"region\": \"oss-cn-shanghai\", \"durationHours\": 12, \"expiration\": \"Thu Sep 23 2021 22:02:21 GMT+0800\", \"accessKey\": \"STS.NSw4TPayxZcbeXQbDfoZiHE16\", \"accessSecret\": \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\", \"stsToken\": \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\", \"authorizedCode\": \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\" } There are two methods to log on to ossbrowser, AK Login and Token Login. a. AK Login You need to fill in the AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken), and Preset Oss Path (uploadPath) as follows: b. Token Login You need to fill in the Auth-Token (authorizedCode) as follows: Then, you will see the following screen\uff1a","title":"2. Log on to ossbrowser"},{"location":"tools/ossbrowser/#3-click-upload-to-upload-files","text":"You can click \"Upload\" button to upload your omics data files and metadata files, and then verify and confirm uploaded files by clicking \"Check\" button in Quartet Data portal website. You only have 12 duration hours, please upload as soon as possible.","title":"3. Click \"Upload\" to upload files"},{"location":"tools/ossutil/","text":"ossutil is a user friendly command line tool to upload data to the Quartet Data Portal. It supports the following operating systems: Windows, Linux, and macOS. You can download and install the ossutil version that best suits your requirements. Name Recommendation Notice Category Characteristics Expected Average Speed OSSUtil High Recommend to use it on a Linux server with wired network Terminal Tool Fast, Powerful and Supporting resuming from a breakpoint 40-100MB/s Click here to download ossutil. Click here to see more details in ossutil. Here is an example that install ossutil on Linux. 1. Download the ossutil installation package \u00b6 wget http://gosspublic.alicdn.com/ossutil/1.7.6/ossutil64 2. Modify the execution permissions of the file \u00b6 chmod 755 ossutil64 3. Generate a configuration file in interactive mode \u00b6 a. Run the following command: ./ossutil64 config b. Configure the path of the configuration file as prompted. Note We recommend that you use the default path for the configuration file by pressing the Enter key. Enter the name of the configuration file. The file name can contain a path. The default path is /home/user/.ossutilconfig. If you press the Enter key without specifying a different name, the file is generated in the default path. If you want to generate the file in another path, set the --config-file configuration item to the path that you want to use. c. Set the language of ossutil as prompted. Note Enter the language: CH or EN. The default language is CH. The configuration of this parameter takes effect after the config command is run. d. Configure the parameters, including Endpoint, AccessKey ID, AccessKey secret, and Security Token Service (STS) token as prompted. The endpoint is http://oss-cn-shanghai.aliyuncs.com. The AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken) are from data.json which is generated by clicking \"New Token\" button in Quartet Data portal website. The contents of the data.json file are as follows: { \"uploadPath\" : \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\" , \"region\" : \"oss-cn-shanghai\" , \"durationHours\" : 12 , \"expiration\" : \"Thu Sep 23 2021 22:02:21 GMT+0800\" , \"accessKey\" : \"STS.NSw4TPayxZcbeXQbDfoZiHE16\" , \"accessSecret\" : \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\" , \"stsToken\" : \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\" , \"authorizedCode\" : \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\" } The parameters are as prompted: Please enter endpoint: http://{region}.aliyuncs.com, such as http://oss-cn-shanghai.aliyuncs.com Please enter accessKeyID: {accessKey}, such as STS.NSw4TPayxZcbeXQbDfoZiHE16 Please enter accessKeySecret: {accessSecret}, such as 38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz Please enter stsToken: {stsToken}, such as CAIS2wR1q6Ft5B2yfSjIr5DCf.... 4. Upload files \u00b6 Run the cp command to upload local files or directories to Object Storage Service (OSS). Click here to see more details in cp. You can verify and confirm uploaded files by clicking \"Check\" button in Quartet Data portal website. You only have 12 duration hours, please upload as soon as possible (But don't worry, when you started the uploading, the process will not be interrupted until finished or killed by you). ./ossutil64 cp -r your_directory oss://quartet-data-portal/data/your@email.address/transcriptomics/","title":"OSSUtil"},{"location":"tools/ossutil/#1-download-the-ossutil-installation-package","text":"wget http://gosspublic.alicdn.com/ossutil/1.7.6/ossutil64","title":"1. Download the ossutil installation package"},{"location":"tools/ossutil/#2-modify-the-execution-permissions-of-the-file","text":"chmod 755 ossutil64","title":"2. Modify the execution permissions of the file"},{"location":"tools/ossutil/#3-generate-a-configuration-file-in-interactive-mode","text":"a. Run the following command: ./ossutil64 config b. Configure the path of the configuration file as prompted. Note We recommend that you use the default path for the configuration file by pressing the Enter key. Enter the name of the configuration file. The file name can contain a path. The default path is /home/user/.ossutilconfig. If you press the Enter key without specifying a different name, the file is generated in the default path. If you want to generate the file in another path, set the --config-file configuration item to the path that you want to use. c. Set the language of ossutil as prompted. Note Enter the language: CH or EN. The default language is CH. The configuration of this parameter takes effect after the config command is run. d. Configure the parameters, including Endpoint, AccessKey ID, AccessKey secret, and Security Token Service (STS) token as prompted. The endpoint is http://oss-cn-shanghai.aliyuncs.com. The AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken) are from data.json which is generated by clicking \"New Token\" button in Quartet Data portal website. The contents of the data.json file are as follows: { \"uploadPath\" : \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\" , \"region\" : \"oss-cn-shanghai\" , \"durationHours\" : 12 , \"expiration\" : \"Thu Sep 23 2021 22:02:21 GMT+0800\" , \"accessKey\" : \"STS.NSw4TPayxZcbeXQbDfoZiHE16\" , \"accessSecret\" : \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\" , \"stsToken\" : \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\" , \"authorizedCode\" : \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\" } The parameters are as prompted: Please enter endpoint: http://{region}.aliyuncs.com, such as http://oss-cn-shanghai.aliyuncs.com Please enter accessKeyID: {accessKey}, such as STS.NSw4TPayxZcbeXQbDfoZiHE16 Please enter accessKeySecret: {accessSecret}, such as 38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz Please enter stsToken: {stsToken}, such as CAIS2wR1q6Ft5B2yfSjIr5DCf....","title":"3. Generate a configuration file in interactive mode"},{"location":"tools/ossutil/#4-upload-files","text":"Run the cp command to upload local files or directories to Object Storage Service (OSS). Click here to see more details in cp. You can verify and confirm uploaded files by clicking \"Check\" button in Quartet Data portal website. You only have 12 duration hours, please upload as soon as possible (But don't worry, when you started the uploading, the process will not be interrupted until finished or killed by you). ./ossutil64 cp -r your_directory oss://quartet-data-portal/data/your@email.address/transcriptomics/","title":"4. Upload files"},{"location":"tools/ossutil_cn/","text":"ossutil \u4e00\u6b3e\u7528\u6237\u53cb\u597d\u7684\u7ec8\u7aef\u547d\u4ee4\u884c\u5de5\u5177\uff0c\u53ef\u7528\u4e8e\u4e0a\u4f20\u6570\u636e\u81f3Quartet Data Portal\u7cfb\u7edf\u3002ossutil\u652f\u6301\u5728Windows\u3001Linux\u3001macOS\u7b49\u7cfb\u7edf\u4e2d\u8fd0\u884c\uff0c\u60a8\u53ef\u4ee5\u6839\u636e\u5b9e\u9645\u73af\u5883\u4e0b\u8f7d\u548c\u5b89\u88c5\u5408\u9002\u7684\u7248\u672c\u3002 \u5de5\u5177\u540d\u79f0 \u63a8\u8350\u7ea7\u522b \u6ce8\u610f\u4e8b\u9879 \u5de5\u5177\u7c7b\u578b \u7279\u70b9 \u9884\u671f\u5e73\u5747\u901f\u5ea6 OSSUtil \u5f3a\u70c8\u63a8\u8350 \u5efa\u8bae\u5728Linux\u670d\u52a1\u5668\u548c\u6709\u7ebf\u7f51\u7edc\u4e0b\u4f7f\u7528 \u7ec8\u7aef\u5de5\u5177 \u652f\u6301\u5927\u91cf\u6587\u4ef6\u5e76\u53d1\u4e0a\u4f20\u3001\u65ad\u70b9\u7eed\u4f20\u53ca\u6587\u4ef6\u76ee\u5f55\uff08\u6587\u4ef6\u5939\uff09\u7684\u4e0a\u4f20 40-100MB/s \u70b9\u51fb \u94fe\u63a5 \u4e0b\u8f7dossutil \u70b9\u51fb \u94fe\u63a5 \u67e5\u770b\u66f4\u591a\u5e2e\u52a9\u4fe1\u606f \u5982\u4e0b\u4ee5Linux\u7248ossutil\u5b89\u88c5\u4e3a\u4f8b\uff0c\u8bf4\u660eossutil\u5b89\u88c5\u4e0e\u4f7f\u7528 1. \u4e0b\u8f7dossutil \u00b6 wget http://gosspublic.alicdn.com/ossutil/1.7.6/ossutil64 2. \u4fee\u6539\u6587\u4ef6\u53ef\u6267\u884c\u6743\u9650 \u00b6 chmod 755 ossutil64 3.\u901a\u8fc7\u4ea4\u4e92\u6a21\u5f0f\u751f\u6210ossutil\u914d\u7f6e\u6587\u4ef6 \u00b6 a. \u8fd0\u884c\u5982\u4e0b\u547d\u4ee4\uff1a ./ossutil64 config b. \u4f9d\u636e\u63d0\u793a\u4fe1\u606f\u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\uff08\u56de\u8f66\u9009\u62e9\u9ed8\u8ba4\u8def\u5f84\u5373\u53ef\uff09 c. \u4f9d\u636e\u63d0\u793a\u9009\u62e9\u8bed\u8a00\uff08\u56de\u8f66\u9009\u62e9\u9ed8\u8ba4\u9009\u9879\u5373\u53ef\uff09 d. \u4f9d\u636e\u63d0\u793a\u914d\u7f6e\u4ee5\u4e0b\u53c2\u6570, \u5305\u62ec Endpoint, AccessKey ID, AccessKey secret, and Security Token Service (STS) token. Endpoint\u586b\u5199 http://oss-cn-shanghai.aliyuncs.com AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken) \u53ef\u4eceQDP\u7cfb\u7edf\u4e0b\u8f7d\u7684 data.json \u6587\u4ef6\u4e2d\u83b7\u53d6\uff0c\u5176\u901a\u8fc7\u70b9\u51fb\"New Token\"\u751f\u6210 data.json\u6587\u4ef6\u793a\u4f8b\u5982\u4e0b\u6240\u793a: { \"uploadPath\" : \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\" , \"region\" : \"oss-cn-shanghai\" , \"durationHours\" : 12 , \"expiration\" : \"Thu Sep 23 2021 22:02:21 GMT+0800\" , \"accessKey\" : \"STS.NSw4TPayxZcbeXQbDfoZiHE16\" , \"accessSecret\" : \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\" , \"stsToken\" : \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\" , \"authorizedCode\" : \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\" } \u53c2\u6570\u793a\u4f8b\u5982\u4e0b: \u8bf7\u8f93\u5165endpoint: http://oss-cn-shanghai.aliyuncs.com \u8bf7\u8f93\u5165accessKeyID: {accessKey}, \u4f8b\u5982\uff1aSTS.NSw4TPayxZcbeXQbDfoZiHE16 \u8bf7\u8f93\u5165accessKeySecret: {accessSecret}, \u4f8b\u5982\uff1a38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz \u8bf7\u8f93\u5165stsToken: {stsToken}, \u4f8b\u5982\uff1aCAIS2wR1q6Ft5B2yfSjIr5DCf.... 4. \u4e0a\u4f20\u6587\u4ef6 \u00b6 \u8fd0\u884cossutil\u7684cp\u547d\u4ee4\u5373\u53ef\u5c06\u672c\u5730\u7684\u6587\u4ef6\u6216\u8005\u76ee\u5f55\u4e0a\u4f20\u81f3QDP\u7cfb\u7edf\u5b58\u50a8\u7cfb\u7edf \u70b9\u51fb \u94fe\u63a5 \u67e5\u770b cp\u547d\u4ee4 \u66f4\u591a\u5e2e\u52a9\u4fe1\u606f \u5728\u786e\u8ba4\u4e0a\u4f20\u5b8c\u6240\u6709\u6587\u4ef6\u540e\uff0c\u8bf7\u56de\u5230QDP\u7f51\u7ad9\uff0c\u70b9\u51fb Check\u6309\u94ae \u786e\u8ba4\u60a8\u7684\u6570\u636e Token\u6709\u6548\u671f\u4e3a12\u5c0f\u65f6\u3002\u4f46\u8bf7\u52ff\u62c5\u5fc3\uff0c\u4e00\u65e6\u6587\u4ef6\u5f00\u59cb\u4e0a\u4f20\u5219\u6574\u4e2a\u8fc7\u7a0b\u4e0d\u4f1a\u53d7Token\u8fc7\u671f\u7684\u5f71\u54cd\uff0c\u9664\u975e\u60a8\u4e3b\u52a8\u7ed3\u675f\u6389\u6216\u8005ossutil\u610f\u5916\u9000\u51fa\u3002\u6b64\u5916\uff0c\u82e5Token\u8fc7\u671f\uff0c\u60a8\u53ef\u4ee5\u56de\u5230QDP\u7f51\u7ad9\u518d\u6b21\u9488\u5bf9\u76f8\u540c\u8def\u5f84\u751f\u6210Token\uff0c\u518d\u6b21\u4e0a\u4f20\u76f8\u5e94\u6587\u4ef6\u3002\u56e0ossutil\u652f\u6301\u65ad\u70b9\u7eed\u4f20\uff0c\u56e0\u6b64\u5c06\u51cf\u8f7bToken\u8fc7\u671f\u5bf9\u60a8\u6570\u636e\u4e0a\u4f20\u6548\u7387\u7684\u5f71\u54cd \u82e5\u60a8\u671f\u671b\u4e0a\u4f20\u6574\u4e2a\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6\uff0c\u8bf7\u6307\u5b9a -r \u53c2\u6570 \u5efa\u8bae\u60a8\u5c3d\u53ef\u80fd\u5c06\u4e00\u6b21\u5206\u6790\u6240\u9700\u7684\u6587\u4ef6\u653e\u5230\u4e0d\u540c\u7684\u5b50\u76ee\u5f55\u4e0b\uff0c\u8fd9\u5c06\u6709\u52a9\u4e8e\u60a8\u540e\u7eed\u6311\u9009\u9884\u671f\u6587\u4ef6\u5b8c\u6210\u5206\u6790 \u82e5\u60a8\u4e0a\u4f20\u6587\u4ef6\u7684\u901f\u5ea6\u5c0f\u4e8e\u9884\u671f\uff0c\u8bf7\u786e\u8ba4\u60a8\u4f7f\u7528\u7684\u662f\u6709\u7ebf\u7f51\u7edc\uff0c\u4e14\u4e3a\u5343\u5146\u7f51\u5361\u3002\u6b64\u5916\uff0c\u60a8\u53ef\u4ee5\u8c03\u6574 --parallel \u4e0e --part-size \u53c2\u6570\u6765\u4f18\u5316 ./ossutil64 cp -r your_directory oss://quartet-data-portal/data/your@email.address/transcriptomics/","title":"OSSUtil\u5feb\u901f\u6307\u5357"},{"location":"tools/ossutil_cn/#1-ossutil","text":"wget http://gosspublic.alicdn.com/ossutil/1.7.6/ossutil64","title":"1. \u4e0b\u8f7dossutil"},{"location":"tools/ossutil_cn/#2","text":"chmod 755 ossutil64","title":"2. \u4fee\u6539\u6587\u4ef6\u53ef\u6267\u884c\u6743\u9650"},{"location":"tools/ossutil_cn/#3ossutil","text":"a. \u8fd0\u884c\u5982\u4e0b\u547d\u4ee4\uff1a ./ossutil64 config b. \u4f9d\u636e\u63d0\u793a\u4fe1\u606f\u6307\u5b9a\u914d\u7f6e\u6587\u4ef6\u5b58\u50a8\u8def\u5f84\uff08\u56de\u8f66\u9009\u62e9\u9ed8\u8ba4\u8def\u5f84\u5373\u53ef\uff09 c. \u4f9d\u636e\u63d0\u793a\u9009\u62e9\u8bed\u8a00\uff08\u56de\u8f66\u9009\u62e9\u9ed8\u8ba4\u9009\u9879\u5373\u53ef\uff09 d. \u4f9d\u636e\u63d0\u793a\u914d\u7f6e\u4ee5\u4e0b\u53c2\u6570, \u5305\u62ec Endpoint, AccessKey ID, AccessKey secret, and Security Token Service (STS) token. Endpoint\u586b\u5199 http://oss-cn-shanghai.aliyuncs.com AccessKeyId (accessKey), AccessKeySecret (accessSecret), STS Token (stsToken) \u53ef\u4eceQDP\u7cfb\u7edf\u4e0b\u8f7d\u7684 data.json \u6587\u4ef6\u4e2d\u83b7\u53d6\uff0c\u5176\u901a\u8fc7\u70b9\u51fb\"New Token\"\u751f\u6210 data.json\u6587\u4ef6\u793a\u4f8b\u5982\u4e0b\u6240\u793a: { \"uploadPath\" : \"oss://quartet-data-portal/data/your@email.address/transcriptomics/\" , \"region\" : \"oss-cn-shanghai\" , \"durationHours\" : 12 , \"expiration\" : \"Thu Sep 23 2021 22:02:21 GMT+0800\" , \"accessKey\" : \"STS.NSw4TPayxZcbeXQbDfoZiHE16\" , \"accessSecret\" : \"38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz\" , \"stsToken\" : \"CAIS2wR1q6Ft5B2yfSjIr5DCf+7kjKZZ7aGJZ37ghkQzY9VFp4Ca1Dz2IHlJdXFgBOEdsf4wlWFR7/wdlrxKVpZfWUHYQcJs56xQ6x+oZ7DGv8HtHWi3dzTiSwapEBfe8JL4kI6bJYqv2J7PBnnAkihsu5uYERypQ12iN7CQlJdjda55dwKkbD1Ado80Qwx5s501OGf2P/SgOQKI523LFxhQpxZbg2Fy4rjdusqH8UjygVn31uIyrYb8KYTecKsKBppkVMqv1+Fbb7fI1DUqiyJH76BrlqdJiwSlj9iWGAtW+A7UcbiWoMRyJRVla7R/F6dYpb3kkudks+iUm43rwlFcIOxMUi3ZS5unxsTsFv6lP9B/eLrmfX/LleqpH67pvhg4Jm4BPQVRcMAgMmN3DB0nUXaYWA/Omj3jZgOkVNLEssUf2oZ0yFPF5MeDI0P1LZySzScfPO1FDSQvLAVE+W36bogMcQFHb0gdUtTzd4hoaw1Eoq7FpBDbUjYarktapPrjffjbyOl9Hoz0RcBBypFPJsYE4XI3Rk7rRq7rhk4IfSl9RqxK2a2XBP3d06OfweOcRe/FB4plvU5BIwjLoiSMWQEDT3z978EqLkuF9t3QxarD6JRmHyMg+9xWC0eIfcsrpFoh2Y2b2Aie6/OkTmqj+HEz4NjA445K6EB/ObWG+7bK52CF4CbIPvlowJaPBTVVLE7pKyAj8pe7nWkaoh0NqWawNisE5k6ZvWTKJ5RGg6TbmyIfXf0MyLWBEm3/5Bh5FNuT/7sXVep+dfhJSOq12RtuwvD3PaENd1wiPn4agAEagz7gU9EpH9fkAUugKbeH9H8ph22NrWAu8WUQF5PPi9CnqP1itUkdDtaTTprv4E5zD3RyWiYH9yA5jn9pYjwvj1tSBXjOCrIo/MLx0DGVSTZ6yExb+SYPNKzaWQ1rloPtKqGWOcXNCOgvYiy8U21Hw8UVzO7EErVAuPvlDNdqWg==\" , \"authorizedCode\" : \"eyJpZCI6IlNUUy5OU3c0VFBheXhaY2JlWFFiRGZvWmlIRTE2Iiwic2VjcmV0IjoiMzhEdlFtRHQ3bzdqa3J0R1hFYWtqWEpNWHZvQWhZRjRjS3NHSlVhWDlMaHoiLCJzdG9rZW4iOiJDQUlTMndSMXE2RnQ1QjJ5ZlNqSXI1RENmKzdraktaWjdhR0paMzdnaGtRelk5VkZwNENhMUR6MklIbEpkWEZnQk9FZHNmNHdsV0ZSN1wvd2RscnhLVnBaZldVSFlRY0pzNTZ4UTZ4K29aN0RHdjhIdEhXaTNkelRpU3dhcEVCZmU4Skw0a0k2YkpZcXYySjdQQm5uQWtpaHN1NXVZRVJ5cFExMmlON0NRbEpkamRhNTVkd0trYkQxQWRvODBRd3g1czUwMU9HZjJQXC9TZ09RS0k1MjNMRnhoUXB4WmJnMkZ5NHJqZHVzcUg4VWp5Z1ZuMzF1SXlyWWI4S1lUZWNLc0tCcHBrVk1xdjErRmJiN2ZJMURVcWl5Skg3NkJybHFkSml3U2xqOWlXR0F0VytBN1VjYmlXb01SeUpSVmxhN1JcL0Y2ZFlwYjNra3Vka3MraVVtNDNyd2xGY0lPeE1VaTNaUzV1bnhzVHNGdjZsUDlCXC9lTHJtZlhcL0xsZXFwSDY3cHZoZzRKbTRCUFFWUmNNQWdNbU4zREIwblVYYVlXQVwvT21qM2paZ09rVk5MRXNzVWYyb1oweUZQRjVNZURJMFAxTFp5U3pTY2ZQTzFGRFNRdkxBVkUrVzM2Ym9nTWNRRkhiMGdkVXRUemQ0aG9hdzFFb3E3RnBCRGJVallhcmt0YXBQcmpmZmpieU9sOUhvejBSY0JCeXBGUEpzWUU0WEkzUms3clJxN3JoazRJZlNsOVJxeEsyYTJYQlAzZDA2T2Z3ZU9jUmVcL0ZCNHBsdlU1Qkl3akxvaVNNV1FFRFQzejk3OEVxTGt1Rjl0M1F4YXJENkpSbUh5TWcrOXhXQzBlSWZjc3JwRm9oMlkyYjJBaWU2XC9Pa1RtcWorSEV6NE5qQTQ0NUs2RUJcL09iV0crN2JLNTJDRjRDYklQdmxvd0phUEJUVlZMRTdwS3lBajhwZTduV2thb2gwTnFXYXdOaXNFNWs2WnZXVEtKNVJHZzZUYm15SWZYZjBNeUxXQkVtM1wvNUJoNUZOdVRcLzdzWFZlcCtkZmhKU09xMTJSdHV3dkQzUGFFTmQxd2lQbjRhZ0FFYWd6N2dVOUVwSDlma0FVdWdLYmVIOUg4cGgyMk5yV0F1OFdVUUY1UFBpOUNucVAxaXRVa2REdGFUVHBydjRFNXpEM1J5V2lZSDl5QTVqbjlwWWp3dmoxdFNCWGpPQ3JJb1wvTUx4MERHVlNUWjZ5RXhiK1NZUE5LemFXUTFybG9QdEtxR1dPY1hOQ09ndllpeThVMjFIdzhVVnpPN0VFclZBdVB2bEROZHFXZz09IiwicHJpdmlsZWdlIjoiUmVhZC1Xcml0ZSIsImV4cGlyYXRpb24iOiIyMDIxLTA5LTIzVDE0OjAyOjIxWiIsIm9zc3BhdGgiOiJvc3M6XC9cL3F1YXJ0ZXQtZGF0YS1wb3J0YWxcL2RhdGFcL3l1ZXFpYW5nc29uZ0BmdWRhbi5lZHUuY25cL1JOQV90ZXN0XC90cmFuc2NyaXB0b21pY3NcLyIsInJlZ2lvbiI6Im9zcy1jbi1zaGFuZ2hhaSIsImR1cmF0aW9uX3NlY29uZHMiOjQzMjAwfQ==\" } \u53c2\u6570\u793a\u4f8b\u5982\u4e0b: \u8bf7\u8f93\u5165endpoint: http://oss-cn-shanghai.aliyuncs.com \u8bf7\u8f93\u5165accessKeyID: {accessKey}, \u4f8b\u5982\uff1aSTS.NSw4TPayxZcbeXQbDfoZiHE16 \u8bf7\u8f93\u5165accessKeySecret: {accessSecret}, \u4f8b\u5982\uff1a38DvQmDt7o7jkrtGXEakjXJMXvoAhYF4cKsGJUaX9Lhz \u8bf7\u8f93\u5165stsToken: {stsToken}, \u4f8b\u5982\uff1aCAIS2wR1q6Ft5B2yfSjIr5DCf....","title":"3.\u901a\u8fc7\u4ea4\u4e92\u6a21\u5f0f\u751f\u6210ossutil\u914d\u7f6e\u6587\u4ef6"},{"location":"tools/ossutil_cn/#4","text":"\u8fd0\u884cossutil\u7684cp\u547d\u4ee4\u5373\u53ef\u5c06\u672c\u5730\u7684\u6587\u4ef6\u6216\u8005\u76ee\u5f55\u4e0a\u4f20\u81f3QDP\u7cfb\u7edf\u5b58\u50a8\u7cfb\u7edf \u70b9\u51fb \u94fe\u63a5 \u67e5\u770b cp\u547d\u4ee4 \u66f4\u591a\u5e2e\u52a9\u4fe1\u606f \u5728\u786e\u8ba4\u4e0a\u4f20\u5b8c\u6240\u6709\u6587\u4ef6\u540e\uff0c\u8bf7\u56de\u5230QDP\u7f51\u7ad9\uff0c\u70b9\u51fb Check\u6309\u94ae \u786e\u8ba4\u60a8\u7684\u6570\u636e Token\u6709\u6548\u671f\u4e3a12\u5c0f\u65f6\u3002\u4f46\u8bf7\u52ff\u62c5\u5fc3\uff0c\u4e00\u65e6\u6587\u4ef6\u5f00\u59cb\u4e0a\u4f20\u5219\u6574\u4e2a\u8fc7\u7a0b\u4e0d\u4f1a\u53d7Token\u8fc7\u671f\u7684\u5f71\u54cd\uff0c\u9664\u975e\u60a8\u4e3b\u52a8\u7ed3\u675f\u6389\u6216\u8005ossutil\u610f\u5916\u9000\u51fa\u3002\u6b64\u5916\uff0c\u82e5Token\u8fc7\u671f\uff0c\u60a8\u53ef\u4ee5\u56de\u5230QDP\u7f51\u7ad9\u518d\u6b21\u9488\u5bf9\u76f8\u540c\u8def\u5f84\u751f\u6210Token\uff0c\u518d\u6b21\u4e0a\u4f20\u76f8\u5e94\u6587\u4ef6\u3002\u56e0ossutil\u652f\u6301\u65ad\u70b9\u7eed\u4f20\uff0c\u56e0\u6b64\u5c06\u51cf\u8f7bToken\u8fc7\u671f\u5bf9\u60a8\u6570\u636e\u4e0a\u4f20\u6548\u7387\u7684\u5f71\u54cd \u82e5\u60a8\u671f\u671b\u4e0a\u4f20\u6574\u4e2a\u76ee\u5f55\u4e0b\u7684\u6587\u4ef6\uff0c\u8bf7\u6307\u5b9a -r \u53c2\u6570 \u5efa\u8bae\u60a8\u5c3d\u53ef\u80fd\u5c06\u4e00\u6b21\u5206\u6790\u6240\u9700\u7684\u6587\u4ef6\u653e\u5230\u4e0d\u540c\u7684\u5b50\u76ee\u5f55\u4e0b\uff0c\u8fd9\u5c06\u6709\u52a9\u4e8e\u60a8\u540e\u7eed\u6311\u9009\u9884\u671f\u6587\u4ef6\u5b8c\u6210\u5206\u6790 \u82e5\u60a8\u4e0a\u4f20\u6587\u4ef6\u7684\u901f\u5ea6\u5c0f\u4e8e\u9884\u671f\uff0c\u8bf7\u786e\u8ba4\u60a8\u4f7f\u7528\u7684\u662f\u6709\u7ebf\u7f51\u7edc\uff0c\u4e14\u4e3a\u5343\u5146\u7f51\u5361\u3002\u6b64\u5916\uff0c\u60a8\u53ef\u4ee5\u8c03\u6574 --parallel \u4e0e --part-size \u53c2\u6570\u6765\u4f18\u5316 ./ossutil64 cp -r your_directory oss://quartet-data-portal/data/your@email.address/transcriptomics/","title":"4. \u4e0a\u4f20\u6587\u4ef6"},{"location":"tools/visualization_tools/","text":"Comming Soon...","title":"Visualization tools"}]}